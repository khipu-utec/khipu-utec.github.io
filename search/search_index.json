{"config": {"lang": ["es"], "separator": "[\\s\\-]+", "pipeline": ["stopWordFilter"]}, "docs": [{"location": "", "title": "KhipuDocs", "text": "<ul> <li> <p>Sobre Khipu</p> <p> Infraestructura  Pol\u00edticas de uso  Grupos de cuentas</p> </li> <li> <p>Primeros Pasos</p> <p> Empeza a usar Khipu  Acceder a Khipu  Transferir archivos</p> </li> <li> <p>Gu\u00eda de Usuario</p> <p> Enviar Jobs  Monitorear Jobs  Ejemplos</p> </li> <li> <p>Software</p> <p> Software Disponible  Uso de software  Instalaci\u00f3n de software</p> </li> <li> <p>Tutoriales</p> <p> Visual Studio remoto  Uso de Apptainer  Reinicio de jobs en Pytorch</p> </li> <li> <p>Enlaces de Inter\u00e9s</p> <p> Website Khipu  Mesa de ayuda</p> </li> </ul>"}, {"location": "anuncios/tags/", "title": "Tags", "text": "<p>Following is a list of relevant tags:</p>"}, {"location": "anuncios/tags/#tag:khipu", "title": "Khipu", "text": "<ul> <li>            Nodo g003 fuera de servicio 14/04/2025          </li> <li>            Nuevo nodo ds001 para Ciencia de Datos          </li> <li>            Reinicio de servicios 22/03/2025          </li> <li>            Suspensi\u00f3n de servicios 19/06/2025          </li> <li>            Suspensi\u00f3n de servicios 22/03/2025          </li> </ul>"}, {"location": "anuncios/tags/#tag:ds001", "title": "ds001", "text": "<ul> <li>            Nuevo nodo ds001 para Ciencia de Datos          </li> </ul>"}, {"location": "anuncios/tags/#tag:g003", "title": "g003", "text": "<ul> <li>            Nodo g003 fuera de servicio 14/04/2025          </li> <li>            Nuevo nodo ds001 para Ciencia de Datos          </li> </ul>"}, {"location": "anuncios/tags/#tag:n006", "title": "n006", "text": "<ul> <li>            Nuevo nodo ds001 para Ciencia de Datos          </li> </ul>"}, {"location": "anuncios/2025/03/22/reinicio-de-servicios-22032025/", "title": "Reinicio de servicios 22/03/2025", "text": "<p>El servicio se encuentra restablecido y operando con normalidad.</p>", "tags": ["Khipu"]}, {"location": "anuncios/2025/03/22/suspensi%C3%B3n-de-servicios-22032025/", "title": "Suspensi\u00f3n de servicios 22/03/2025", "text": "<p>El servicio se encuentra suspendido por una interrupci\u00f3n del suministro el\u00e9ctrico. Se espera que el servicio sea restablesca en las pr\u00f3ximas horas.</p>", "tags": ["Khipu"]}, {"location": "anuncios/2025/04/14/nodo-g003-fuera-de-servicio-14042025/", "title": "Nodo g003 fuera de servicio 14/04/2025", "text": "<p>El d\u00eda de hoy el nodo g003 estar\u00e1 fuera de servicio debido a trabajos de actualizaci\u00f3n.</p>", "tags": ["Khipu", "g003"]}, {"location": "anuncios/2025/04/15/nuevo-nodo-ds001-para-ciencia-de-datos/", "title": "Nuevo nodo ds001 para Ciencia de Datos", "text": "<p>El d\u00eda de hoy se a\u00f1adi\u00f3 un nuevo nodo a Khipu llamado ds001. De manera temporal se traslad\u00f3 la gpu del nodo g003 al ds001. A ra\u00edz de estos cambios, el nodo g003 pasar\u00e1 a llamarse n006 y permanecer\u00e1 en las particiones standard y big-mem. El nuevo nodo ds001 estar\u00e1 en la partici\u00f3n data-science. </p> <p>Este nuevo nodo posee las siguientes caracter\u00edsticas:</p> Especificaciones Procesador Intel(R) Xeon(R) Gold 5418Y 2.0 GHz 24 cores por socket, 48 por nodo.  Gr\u00e1ficos NVIDIA RTX A6000 48 GB GDDR6 Memoria  1TB DRAM DDR5 5600MHz Red Infiniband Mellanox MT28908", "tags": ["Khipu", "ds001", "g003", "n006"]}, {"location": "anuncios/2025/06/19/suspensi%C3%B3n-de-servicios-19062025/", "title": "Suspensi\u00f3n de servicios 19/06/2025", "text": "<p>Los servicios del cluster ser\u00e1n suspendidos el d\u00eda <code>19/06/2025</code> debido a trabajos de mantenimiento.  Se estar\u00e1 comunicando cuando se restablezcan los servicios.</p>", "tags": ["Khipu"]}, {"location": "guia-de-usuario/comandos-basicos/", "title": "Comandos b\u00e1sicos de SLURM", "text": "<p>{{% steps %}}</p>"}, {"location": "guia-de-usuario/comandos-basicos/#srun-ejecutar-trabajos", "title": "<code>srun</code> - Ejecutar trabajos", "text": "<p>El comando <code>srun</code> es utilizado para ejecutar jobs de manera directa o interactiva. Se puede especificar cu\u00e1ntos nodos, CPUs, memoria, etc., se requiere utilizar.</p> <p>Sintaxis b\u00e1sica:</p> <p><pre><code>srun [opciones] [comando]\n</code></pre> Ejemplo: Ejecutar un script en un solo nodo con una CPU:</p> <pre><code>srun -n 1 --ntasks=1 --cpus-per-task=1 bash mi_script.sh\n</code></pre> <p>Donde <code>mi_script.sh</code> contiene lo siguiente:</p> <p><pre><code>#!/bin/bash\n\necho \"Iniciando en $(date)\"\necho \"El job fue enviado a la partici\u00f3n ${SLURM_JOB_PARTITION}\"\necho \"Nombre del job: ${SLURM_JOB_NAME}, Job ID: ${SLURM_JOB_ID}\"\necho \"Tengo ${SLURM_CPUS_ON_NODE} CPUs en el nodo $(hostname)\"\necho \"Voy a dormir 10s para que me veas en la fila\"\nsleep 10 \n</code></pre> Al pedir un job interactivo, se reservaran los recursos y se iniciar\u00e1 sesi\u00f3n en un shell de alguno de los nodos de c\u00f3mputo. </p> <p>Ejemplo: Reservar un nodo de manera interactiva:</p> <p><pre><code>srun --pty -t 2:00 --mem=2G -p debug bash\n</code></pre> El comando anterior asignar\u00e1 un CPU y 2GiB RAM por un periodo de 2 minutos. Durante ese tiempo podremos ejecutar comandos dentro de la shell de manera interactiva. Para salir de la sesi\u00f3n, deberemos ejecutar <code>exit</code> o presionar <code>Ctrl</code>+<code>d</code>.</p>"}, {"location": "guia-de-usuario/comandos-basicos/#sbatch-enviar-trabajos-a-la-cola", "title": "<code>sbatch</code> - Enviar trabajos a la cola", "text": "<p>El comando sbatch se utiliza para enviar un trabajo a la cola de SLURM. Este comando es ideal para trabajos que se ejecutan en segundo plano, como tareas largas o de alto rendimiento.</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>sbatch [opciones] [archivo_de_script]\n</code></pre> <p>Ejemplo: Enviar un trabajo de script:</p> <pre><code>sbatch mi_script.sb\n</code></pre>"}, {"location": "guia-de-usuario/comandos-basicos/#squeue-ver-el-estado-de-los-trabajos", "title": "<code>squeue</code> - Ver el estado de los trabajos", "text": "<p>El comando squeue muestra los trabajos en ejecuci\u00f3n y en espera en la cola de SLURM. Con ese comando nuede ver el estado de tus trabajos, qu\u00e9 partitici\u00f3n y nodos est\u00e1n utilizando, etc.</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>squeue [opciones]\n</code></pre> <p>Ejemplo: Ver los trabajos que he enviado:</p> <p><pre><code>squeue --me\n</code></pre> Con ello obtendr\u00e9 una salida parecida a:</p> <pre><code>[alan.turing@khipu ~]$ squeue\nJOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n1077     debug  CudaJob  alan.turing  R       0:02      1 n005\n</code></pre>"}, {"location": "guia-de-usuario/comandos-basicos/#scancel-cancelar-trabajos", "title": "<code>scancel</code> - Cancelar trabajos", "text": "<p>Este comando te permite cancelar trabajos en ejecuci\u00f3n o en espera en la cola.</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>scancel [opciones] [job_id]\n</code></pre> <p>Ejemplo: Cancelar un trabajo con un ID espec\u00edfico:</p> <pre><code>scancel 1077\n</code></pre>"}, {"location": "guia-de-usuario/comandos-basicos/#scontrol-controlar-y-gestionar-trabajos", "title": "<code>scontrol</code> - Controlar y gestionar trabajos", "text": "<p>El comando scontrol le permite obtener informaci\u00f3n detallada sobre trabajos o recursos, y realizar operaciones de control (pausar, reanudar, etc.).</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>scontrol [opciones] [comando]\n</code></pre> <p>Ejemplo: Ver el estado de un trabajo:</p> <pre><code>scontrol show job 1077\n</code></pre> <p>Con ello obtendr\u00e9 una salida parecida a:</p> <pre><code>[alan.turing@khipu ~]$ scontrol show job 1077\nJobId=1077 JobName=CudaJob\n   UserId=alan.turing(1000) GroupId=alan.turing(1000) MCS_label=N/A\n   Priority=1683 Nice=0 Account=pregrado QOS=a-pregrado\n   JobState=COMPLETED Reason=None Dependency=(null)\n   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n   RunTime=00:00:02 TimeLimit=00:10:00 TimeMin=N/A\n   SubmitTime=2024-11-06T02:41:48 EligibleTime=2024-11-06T02:41:48\n   AccrueTime=2024-11-06T02:41:48\n   StartTime=2024-11-06T02:41:48 EndTime=2024-11-06T02:41:50 Deadline=N/A\n   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2024-11-06T02:41:48 Scheduler=Main\n   Partition=debug AllocNode:Sid=khipu:2943597\n   ReqNodeList=(null) ExcNodeList=(null)\n   NodeList=n005\n   BatchHost=n005\n   NumNodes=1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\n   ReqTRES=cpu=1,mem=100M,node=1,billing=1\n   AllocTRES=cpu=1,mem=100M,node=1,billing=1\n   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\n   MinCPUsNode=1 MinMemoryCPU=100M MinTmpDiskNode=0\n   Features=(null) DelayBoot=00:00:00\n   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\n   Command=/home/alan.turing/gpu_job_shard.sh\n   WorkDir=/home/alan.turing\n   StdErr=/home/alan.turing/slurm-1077.out\n   StdIn=/dev/null\n   StdOut=/home/alan.turing/slurm-1077.out\n   Power=\n</code></pre>"}, {"location": "guia-de-usuario/comandos-basicos/#sinfo-ver-informacion-sobre-los-nodos-y-particiones", "title": "<code>sinfo</code> - Ver informaci\u00f3n sobre los nodos y particiones", "text": "<p>Con sinfo puede obtener informaci\u00f3n sobre las particiones, su estado y nodos disponibles en el sistema.</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>sinfo [opciones]\n</code></pre> <p>Ejemplo: Ver el estado de las particiones:</p> <p><pre><code>sinfo\n</code></pre> Ejemplo: Ver el estado de las particiones y la raz\u00f3n de dicho estado:</p> <pre><code>sinfo -R\n</code></pre> <p>{{% /steps %}}</p>"}, {"location": "guia-de-usuario/creacion-de-script/", "title": "Creaci\u00f3n de Script", "text": "<p>Para trabajos m\u00e1s complejos o largos, es com\u00fan escribir un script que contiene instrucciones de SLURM y las tareas que deseas ejecutar.</p> <p>Ejemplo de un script b\u00e1sico (mi_script.sb):</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=mi_trabajo    # Nombre del trabajo\n#SBATCH --output=mi_trabajo.out  # Archivo de salida\n#SBATCH --error=mi_trabajo.err   # Archivo de error\n#SBATCH --ntasks=1               # N\u00famero de tareas (procesos)\n#SBATCH --cpus-per-task=4        # CPUs por tarea\n#SBATCH --mem=8G                 # Memoria por nodo\n#SBATCH --time=0-00:10:00        # Tiempo m\u00e1ximo de ejecuci\u00f3n (day-hour:min:sec)\n#SBATCH --partition=debug        # Partici\u00f3n a usar\n#SBATCH --mail-type=END,FAIL     # Cuando se enviar\u00e1 un mail\n#SBATCH --mail-user=miusuario@example.com\n\n\n# Cargar m\u00f3dulos, si es necesario\nmodule load python3/3.10\n\n# Ejecutar el script o comando\npython mi_script_python.py\n</code></pre> <p>Explicaci\u00f3n de las opciones:</p> <ul> <li><code>--job-name</code>: El nombre del trabajo.</li> <li><code>--output</code>: Archivo donde se guardar\u00e1 la salida est\u00e1ndar.</li> <li><code>--error</code>: Archivo donde se guardar\u00e1n los errores.</li> <li><code>--ntasks</code>: N\u00famero de tareas (por ejemplo, procesos a ejecutar).</li> <li><code>--cpus-per-task</code>: N\u00famero de CPUs por tarea.</li> <li><code>--mem</code>: Cantidad de memoria por nodo.</li> <li><code>--time</code>: Tiempo m\u00e1ximo para ejecutar el trabajo.</li> <li><code>--partition</code>: Especifica en qu\u00e9 partici\u00f3n se ejecutar\u00e1 el trabajo. Mayor informaci\u00f3n sobre las particiones disponibles aqu\u00ed</li> <li><code>--mail-type</code>: Especifica en que estados del job enviar un correo. En el ejemplo se env\u00eda al terminar <code>END</code> o cuando falle <code>FAIL</code>.</li> <li><code>--mail-user</code>: Correo electr\u00f3nico al cual se notificar\u00e1 el cambio de estado del job.</li> </ul> <p>A estas opciones se les conoce como job request. La lista de job request disponibles las encuentra aqu\u00ed.</p> <p>Enviar el trabajo con sbatch:</p> <pre><code>sbatch mi_script.sb\n</code></pre> <p>Es posible sobreescribir las opciones escritas en el script al momento de enviar el trabajo.</p> <p>Enviar el trabajo con sbatch a una particion distinta:</p> <pre><code>sbatch -p gpu-debug mi_script.sb\n</code></pre> <p>En el ejemplo anterior se cambio la partici\u00f3n inicial de <code>debug</code> a <code>gpu-debug</code>.</p>"}, {"location": "guia-de-usuario/job-request/", "title": "Job Request", "text": "<p>Las siguientes opciones modifican el tama\u00f1o, largo y el comportamiento del job que se env\u00eda. Estos pueden especificarse llamando a <code>srun</code> o <code>sbatch</code>, o dentro de un batch job. Si se especifican al mismo tiempo las opciones en los argumentos de <code>sbatch</code> y en el script del batch job, las opciones pasadas al comando <code>sbatch</code> ser\u00e1n las que se tomar\u00e1n en cuenta. Si no se especifica valor para alguna de las opciones, los valores por defecto ser\u00e1n los que se empleen. </p>    | Opci\u00f3n Larga | Opci\u00f3n Corta | Valor por Defecto | Descripci\u00f3n | | --- | --- | --- | --- | | `--job-name` | `-J` | Nombre del archivo  | Nombre de job personalizado. | | `--output` | `-o` | `\"slurm-%j.out\"` | Nombre del archivo donde se guadar\u00e1 la salida `stdout` o `stderr`. Mayores patrones de nombre [aqu\u00ed](https://slurm.schedmd.com/sbatch.html#SECTION_%3CB%3Efilename-pattern%3C/B%3E). | | `--error` | `-e` | Se escribe en el mismo archivo del `--output` | Nombre del archivo donde se guadar\u00e1n los logs de ;ps errores. | | `--partition` | `-p` | `debug`  | Se\u00f1ala la partici\u00f3n donde se va a ejecutar el job. | | `--time` | `-t` | Var\u00eda de acuerda a la partici\u00f3n y tipo de usuario | L\u00edmite de tiempo para el job en el formato `D-HH:MM:SS`. Por ejemplo,  `-t 1-` es un d\u00eda de ejecuci\u00f3n y `-t 4:00:00` son 4 horas. | | `--nodes` | `-N` | 1 | N\u00famero total de nodos. | | `--ntasks` | `-n` | 1 | N\u00famero de tareas (workers MPI). | | `--ntasks-per-node` | | El scheduler lo decide | N\u00famero de tareas por nodo. | | `--cpus-per-task` | `-c` | 1 | N\u00famero de cores de CPUs para cada tarea. Use esto para threads/cores en un job de nodo \u00fanico. | | `--mem-per-cpu` | | `5G` | Cantidad de memoria RAM requerida por CPU en MiB. Si se especifica en GiB usar `G`(ej. `10G`). | | `--mem` | | | Memoria pedida por nodo en MiB. Si se especifica en GiB usar `G`(ej. `10G`). | | `--mail-user` | | Tu email de UTEC | Direcci\u00f3n de correo a donde enviar notificaciones del job. | | `--mail-type` | | Ninguna | Env\u00eda un mail cada vez que un job cambia de estado. Utilice la opci\u00f3n `ALL` para recibir notificaciones al iniciar y terminar un job. Opciones disponibles `ALL`, `BEGIN`, `END`, `FAIL`, `NONE` |"}, {"location": "guia-de-usuario/monitorear/", "title": "Monitorear recursos", "text": ""}, {"location": "guia-de-usuario/monitorear/#recomendacion-general", "title": "Recomendaci\u00f3n General \ud83d\udca1", "text": "<p>Aseg\u00farese de reservar la cantidad de RAM y CPUs necesarios para la ejecuci\u00f3n de su job. No reserve recursos que no necesita, ya que de hacerlo, perjudicar\u00e1 la ejecuci\u00f3n de los dem\u00e1s usuarios del cluster. </p> <p>A continuaci\u00f3n, se muestran algunos ejemplos de como medir el uso de CPU y RAM de su job a fin de que pueda refinar la reserva de recursos.  No olvide revisar la documentaci\u00f3n sobre el env\u00edo de jobs a Slurm.</p>"}, {"location": "guia-de-usuario/monitorear/#jobs-en-ejecucion", "title": "Jobs en ejecuci\u00f3n", "text": "<p>Si su job se encuentra en ejecuci\u00f3n, usted puede revisar su uso actual de recursos. Sin embargo, deber\u00e1 esperar hasta su finalizaci\u00f3n para ver el uso m\u00e1ximo de recursos durante toda su ejecuci\u00f3n. </p> <p>La manera m\u00e1s sencilla de revisar el uso instant\u00e1neo de recursos es hacer crear un job interactivo en el nodo de computaci\u00f3n donde su job se encuentra ejecut\u00e1ndose. Para saber en que nodo debe crear el job interactivo, ejecute:</p> <p><pre><code>squeue --me\n</code></pre> El cual nos da como salida:  <pre><code>JOBID PARTITION     NAME     USER  ST       TIME  NODES NODELIST(REASON)\n21615 standard    bert-sar juan   PD       0:00      1 n003\n</code></pre></p> <p>En ella podemos notar que su job bert-sar se encuentra ejecutandose en el nodo <code>n003</code> de la parici\u00f3n <code>standard</code>. Con esa informaci\u00f3n crearemos el job interactivo.</p> <pre><code>srun --pty -t 02:00 --mem=8G -p standard --nodelist=n003 bash\n</code></pre> <p>Una vez dentro del nodo de c\u00f3mputo, ejecutaremos <code>ps</code> o <code>htop</code>.</p> <ul> <li> <p><code>ps</code> le brindar\u00e1 la informaci\u00f3n instant\u00e1nea del uso de recursos cada vez que ejecute el comando. </p> <pre><code>[alan.turing@n004 ~]$ ps -u$USER -o %cpu,rss,args\n%CPU   RSS COMMAND\n0.0  2376 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n</code></pre> <p>El reporte de memoria de <code>ps</code> se muestra en KB, podemos notar que los procesos listados consumen alrededor de 2000 KB de RAM y que el uso de los CPUs es casi nulo.</p> </li> <li> <p><code>htop</code> se ejecuta de manera interactiva y muestra las estad\u00edsticas de uso en vivo. Puede presionar la tecla <code>u</code>, ingresar su nombre de usuario y luego <code>enter</code> para filtrar solo sus procesos. La informaci\u00f3n del uso de memoria, se encuentra en la columna RES. Para solicitar ayuda puede presionar <code>?</code> y si desea salir <code>q</code> .</p> </li> </ul> <p> </p>"}, {"location": "guia-de-usuario/monitorear/#jobs-finalizados", "title": "Jobs finalizados", "text": "<p>Slurm guarda las estad\u00edsticas de cada job, inclu\u00eddo cuanta memoria y CPU fue utilizada. &lt;!-- </p>"}, {"location": "guia-de-usuario/monitorear/#seff", "title": "seff", "text": "<ul> <li>Luego de finalizado un job, puede ejecutar <code>seff&lt;jobid&gt;</code> para obtener informaci\u00f3n \u00fatil sobre la ejecuci\u00f3n de su job, tal como la memoria usada y a que porcentaje de la memoria reserva corresponde.</li> </ul> <p><pre><code>[alan.turing@khipu ~]$ seff 21886\nJob ID: 21886\nCluster: cluster\nUse of uninitialized value $group in concatenation (.) or string at /usr/bin/seff line 154, &lt;DATA&gt; line 602.\nUser/Group: alan.turing/\nState: COMPLETED (exit code 0)\nCores: 1\nCPU Utilized: 00:00:00\nCPU Efficiency: 0.00% of 00:00:00 core-walltime\nJob Wall-clock time: 00:00:00\nMemory Utilized: 0.00 MB (estimated maximum)\nMemory Efficiency: 0.00% of 50.00 GB (50.00 GB/core)\n``` --&gt;\n\n#### sacct\n\nTambi\u00e9n se puede usar `sacct` para obtener la informaci\u00f3n del job. Lamentablemente, el output por defecto de `sacct` no es del todo entendible, por ello se recomienda procesar la salida de la siguiente manera. \n</code></pre> [alan.turing@khipu ~]$ export SACCT_FORMAT=\"JobID%20,JobName,User,Partition,NodeList,Elapsed,State,ExitCode,MaxRSS,AllocTRES%32\" [alan.turing@khipu ~]$ sacct -j 21886      JobID    JobName      User  Partition        NodeList    Elapsed      State ExitCode     MaxRSS                        AllocTRES </p> <pre><code>  1063 simple_ex+   alan.tur+      debug            n005   00:00:11  COMPLETED      0:0             billing=2,cpu=2,mem=200M,node=1\n</code></pre> <p>1063.batch      batch                                 n005   00:00:11  COMPLETED      0:0                       cpu=2,mem=200M,node=1  ```</p>"}, {"location": "guia-de-usuario/particiones/", "title": "Particiones", "text": "<p>Las particiones pueden ser consideradas como colas de trabajos, cada una de ellas con sus propios l\u00edmites en cuanto al tama\u00f1o y la duraci\u00f3n del job. Khipu posee cinco diferentes particiones en slurm.</p> Nombre de partici\u00f3n Descripci\u00f3n debug partici\u00f3n para probar ejecuciones peque\u00f1as en CPU con prop\u00f3sitos de debugging debug-gpu partici\u00f3n para probar ejecuciones peque\u00f1as en GPU con prop\u00f3sitos de debugging standard partici\u00f3n de uso general en CPU big-mem partici\u00f3n de uso general en CPU con gran cantidad de memoria gpu partici\u00f3n de uso general en GPU <p>El n\u00famero y el tama\u00f1o de los jobs permitidos depende de acuerdo a la partici\u00f3n seleccionada y su tipo de usuario. </p> <p>Para listar las particiones que se encuentran disponibles para sua usuario, ejecute el comando:</p> <pre><code>sinfo -O \"partition\"     \n</code></pre>"}, {"location": "guia-de-usuario/particiones/#detalles-de-las-particiones", "title": "Detalles de las particiones", "text": "Partici\u00f3n Nodos Total de Cores Total de Memoria RAM (GB) Total shards de GPU M\u00e1x duraci\u00f3n del Job (min) debug n005 16 32 - 30 debug-gpu g001 12 60 12 30 standard n00[3-5] 80 352 - depende del tipo de usuario big-mem g00[2-3], ag001 54 2470 - depende del tipo de usuario gpu g00[1-3], ag001 190 630 190 depende del tipo de usuario"}, {"location": "guia-de-usuario/particiones/#debug", "title": "debug", "text": "<p>Tiempos de espera m\u00e1s cortos y tiempo de ejecuci\u00f3n peque\u00f1o. Utilice esta partici\u00f3n para probar la ejecuci\u00f3n de su job antes de enviarlo a una partici\u00f3n de m\u00e1s recursos.</p>"}, {"location": "guia-de-usuario/particiones/#debug-gpu", "title": "debug-gpu", "text": "<p>Tiempos de espera m\u00e1s cortos y tiempo de ejecuci\u00f3n peque\u00f1o. Utilice esta partici\u00f3n para probar la ejecuci\u00f3n de su job en GPU antes de enviarlo a una partici\u00f3n de m\u00e1s recursos.</p>"}, {"location": "guia-de-usuario/particiones/#standard", "title": "standard", "text": "<p>Partici\u00f3n de uso general para tareas que requieren cores de CPU. Utilice esta partici\u00f3n para ejecutar tareas intensas en uso de CPU. Los tiempos de espera en cola depender\u00e1n de la cantidad de usuarios que se encuentren usando la partici\u00f3n. Procure dimensionar correctamente su trabajo para disminuir su tiempo de espera en la cola. Use la partici\u00f3n <code>debug</code> para dicho prop\u00f3sito.</p>"}, {"location": "guia-de-usuario/particiones/#big-mem", "title": "big-mem", "text": "<p>Partici\u00f3n de uso general para tareas que requieren cores de CPU y gran cantidad de memoria RAM. Utilice esta partici\u00f3n para ejecutar tareas intensas en memoria. Los tiempos de espera en cola depender\u00e1n de la cantidad de usuarios que se encuentren usando la partici\u00f3n. Procure dimensionar correctamente su trabajo para disminuir su tiempo de espera en la cola. Use la partici\u00f3n <code>debug</code> para dicho prop\u00f3sito.</p>"}, {"location": "guia-de-usuario/particiones/#gpu", "title": "gpu", "text": "<p>Partici\u00f3n de uso general para tareas que requieren cores de GPU. Es una de las particiones de mayor demanda en Khipu, es por ese motivo que no es posible reservar GPUs de manera exclusiva. El uso de la GPU es compartido a traves de sharding. Los tiempos de espera en cola depender\u00e1n de la cantidad de usuarios que se encuentren usando la partici\u00f3n. Procure dimensionar correctamente su trabajo para disminuir su tiempo de espera en la cola. Use la partici\u00f3n <code>debug-gpu</code> para dicho prop\u00f3sito.</p>"}, {"location": "guia-de-usuario/ejecutar-jobs/", "title": "Ejecutar jobs", "text": "<p>\u00a1El nodo de acceso no es para realizar c\u00f3mputos!</p> <p>El nodo de acceso es compartido por todos los usuarios y no debe ser usado para ejecutar tareas intensas. Esas tareas deben ser enviadas al gestor de Slurm para que este asigne un nodo de c\u00f3mputo donde ejecutarse.</p> <p>Dado que Khipu es un recurso compartido, hacemos uso de un gestor de recursos como Slurm que nos permitir\u00e1  enviar, cancelar y revisar cargas de trabajo o jobs.</p>"}, {"location": "guia-de-usuario/ejecutar-jobs/#slurm", "title": "Slurm", "text": "<p>Simple Linux Utility of Resource Mangement (Slurm), es el encargado de coordinar los recursos de todos los nodos del cluster y asignarlos de acuerdo la prioridad de los jobs, cantidad de recursos solicitados y cantidad de recursos disponibles.</p> <p>A continuaci\u00f3n, se proporciona una gu\u00eda b\u00e1sica sobre c\u00f3mo utilizar SLURM para ejecutar trabajos en Khipu.</p>"}, {"location": "guia-de-usuario/ejecutar-jobs/#1-comandos-basicos-de-slurm", "title": "1. Comandos B\u00e1sicos de SLURM", "text": ""}, {"location": "guia-de-usuario/ejecutar-jobs/#11-srun-ejecutar-trabajos", "title": "1.1. <code>srun</code> - Ejecutar trabajos", "text": "<p>El comando <code>srun</code> es utilizado para ejecutar jobs de manera directa o interactiva. Se puede especificar cu\u00e1ntos nodos, CPUs, memoria, etc., se requiere utilizar.</p> <p>Sintaxis b\u00e1sica:</p> <p><pre><code>srun [opciones] [comando]\n</code></pre> Ejemplo: Ejecutar un script en un solo nodo con una CPU:</p> <pre><code>srun -n 1 --ntasks=1 --cpus-per-task=1 bash mi_script.sh\n</code></pre> <p>Donde <code>mi_script.sh</code> contiene lo siguiente:</p> <p><pre><code>#!/bin/bash\n\necho \"Iniciando en $(date)\"\necho \"El job fue enviado a la partici\u00f3n ${SLURM_JOB_PARTITION}\"\necho \"Nombre del job: ${SLURM_JOB_NAME}, Job ID: ${SLURM_JOB_ID}\"\necho \"Tengo ${SLURM_CPUS_ON_NODE} CPUs en el nodo $(hostname)\"\necho \"Voy a dormir 10s para que me veas en la fila\"\nsleep 10 \n</code></pre> Al pedir un job interactivo, se reservaran los recursos y se iniciar\u00e1 sesi\u00f3n en un shell de alguno de los nodos de c\u00f3mputo. </p> <p>Ejemplo: Reservar un nodo de manera interactiva:</p> <p><pre><code>srun --pty -t 2:00 --mem=2G -p debug bash\n</code></pre> El comando anterior asignar\u00e1 un CPU y 2GiB RAM por un periodo de 2 minutos. Durante ese tiempo podremos ejecutar comandos dentro de la shell de manera interactiva. Para salir de la sesi\u00f3n, deberemos ejecutar <code>exit</code> o presionar <code>Ctrl</code>+<code>d</code>.</p>"}, {"location": "guia-de-usuario/ejecutar-jobs/#12-sbatch-enviar-trabajos-a-la-cola", "title": "1.2. <code>sbatch</code> - Enviar trabajos a la cola", "text": "<p>El comando sbatch se utiliza para enviar un trabajo a la cola de SLURM. Este comando es ideal para trabajos que se ejecutan en segundo plano, como tareas largas o de alto rendimiento.</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>sbatch [opciones] [archivo_de_script]\n</code></pre> <p>Ejemplo: Enviar un trabajo de script:</p> <pre><code>sbatch mi_script.sb\n</code></pre>"}, {"location": "guia-de-usuario/ejecutar-jobs/#13-squeue-ver-el-estado-de-los-trabajos", "title": "1.3. <code>squeue</code> - Ver el estado de los trabajos", "text": "<p>El comando squeue muestra los trabajos en ejecuci\u00f3n y en espera en la cola de SLURM. Con ese comando nuede ver el estado de tus trabajos, qu\u00e9 partitici\u00f3n y nodos est\u00e1n utilizando, etc.</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>squeue [opciones]\n</code></pre> <p>Ejemplo: Ver los trabajos que he enviado:</p> <p><pre><code>squeue --me\n</code></pre> Con ello obtendr\u00e9 una salida parecida a:</p> <pre><code>[alan.turing@khipu ~]$ squeue\nJOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n1077     debug  CudaJob  alan.turing  R       0:02      1 n005\n</code></pre>"}, {"location": "guia-de-usuario/ejecutar-jobs/#14-scancel-cancelar-trabajos", "title": "1.4. <code>scancel</code> - Cancelar trabajos", "text": "<p>Este comando te permite cancelar trabajos en ejecuci\u00f3n o en espera en la cola.</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>scancel [opciones] [job_id]\n</code></pre> <p>Ejemplo: Cancelar un trabajo con un ID espec\u00edfico:</p> <pre><code>scancel 1077\n</code></pre>"}, {"location": "guia-de-usuario/ejecutar-jobs/#15-scontrol-controlar-y-gestionar-trabajos", "title": "1.5. <code>scontrol</code> - Controlar y gestionar trabajos", "text": "<p>El comando scontrol le permite obtener informaci\u00f3n detallada sobre trabajos o recursos, y realizar operaciones de control (pausar, reanudar, etc.).</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>scontrol [opciones] [comando]\n</code></pre> <p>Ejemplo: Ver el estado de un trabajo:</p> <pre><code>scontrol show job 1077\n</code></pre> <p>Con ello obtendr\u00e9 una salida parecida a:</p> <pre><code>[alan.turing@khipu ~]$ scontrol show job 1077\nJobId=1077 JobName=CudaJob\n   UserId=alan.turing(1000) GroupId=alan.turing(1000) MCS_label=N/A\n   Priority=1683 Nice=0 Account=pregrado QOS=a-pregrado\n   JobState=COMPLETED Reason=None Dependency=(null)\n   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n   RunTime=00:00:02 TimeLimit=00:10:00 TimeMin=N/A\n   SubmitTime=2024-11-06T02:41:48 EligibleTime=2024-11-06T02:41:48\n   AccrueTime=2024-11-06T02:41:48\n   StartTime=2024-11-06T02:41:48 EndTime=2024-11-06T02:41:50 Deadline=N/A\n   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2024-11-06T02:41:48 Scheduler=Main\n   Partition=debug AllocNode:Sid=khipu:2943597\n   ReqNodeList=(null) ExcNodeList=(null)\n   NodeList=n005\n   BatchHost=n005\n   NumNodes=1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\n   ReqTRES=cpu=1,mem=100M,node=1,billing=1\n   AllocTRES=cpu=1,mem=100M,node=1,billing=1\n   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\n   MinCPUsNode=1 MinMemoryCPU=100M MinTmpDiskNode=0\n   Features=(null) DelayBoot=00:00:00\n   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\n   Command=/home/alan.turing/gpu_job_shard.sh\n   WorkDir=/home/alan.turing\n   StdErr=/home/alan.turing/slurm-1077.out\n   StdIn=/dev/null\n   StdOut=/home/alan.turing/slurm-1077.out\n   Power=\n</code></pre>"}, {"location": "guia-de-usuario/ejecutar-jobs/#16-sinfo-ver-informacion-sobre-los-nodos-y-particiones", "title": "1.6. <code>sinfo</code> - Ver informaci\u00f3n sobre los nodos y particiones", "text": "<p>Con sinfo puede obtener informaci\u00f3n sobre las particiones, su estado y nodos disponibles en el sistema.</p> <p>Sintaxis b\u00e1sica:</p> <pre><code>sinfo [opciones]\n</code></pre> <p>Ejemplo: Ver el estado de las particiones:</p> <p><pre><code>sinfo\n</code></pre> Ejemplo: Ver el estado de las particiones y la raz\u00f3n de dicho estado:</p> <pre><code>sinfo -R\n</code></pre>"}, {"location": "guia-de-usuario/ejemplos/gpu/", "title": "GPU", "text": ""}, {"location": "guia-de-usuario/ejemplos/introductorios/", "title": "Introductorios", "text": ""}, {"location": "guia-de-usuario/ejemplos/introductorios/#imprimir-la-fecha-actual", "title": "Imprimir la fecha actual", "text": "<ol> <li>Crear el archivo fecha_actual.sh:</li> </ol> <pre><code>#!/bin/bash\n\n# Nombre del job:\n#SBATCH --job-name=fecha_actual \n\n# Cantidad de CPUs cores a usar:\n#SBATCH -c 1\n\n# Tama\u00f1o de memoria del job:\n#SBATCH --mem-per-cpu=100mb\n\ndate\nsleep 10 # duerme 10s, solo para visualizar el job en la fila\n</code></pre> <ol> <li>Enviar a ejecutar el job:</li> </ol> <pre><code>sbatch fecha_actual.sh\n</code></pre>"}, {"location": "guia-de-usuario/ejemplos/introductorios/#imprimir-las-variables-de-ambiente-de-slurm", "title": "Imprimir las variables de ambiente de Slurm", "text": "<ol> <li>Crear el archivo env_vars.sh:</li> </ol> <pre><code>#!/bin/bash\n\n# Nombre del job:\n#SBATCH --job-name=env_vars \n\n# Comandos:\nset | grep SLURM\n</code></pre> <ol> <li>Enviar a ejecutar el job:</li> </ol> <pre><code>sbatch env_vars.sh\n</code></pre>"}, {"location": "guia-de-usuario/ejemplos/miniconda/", "title": "Miniconda", "text": "<p>En Khipu, se puede emplear el gestor de paquetes <code>conda</code> a trav\u00e9s del m\u00f3dulo <code>Miniconda</code>. Para ello ser\u00e1 necesario necesario ejecutar los siguiente pasos:</p>"}, {"location": "guia-de-usuario/ejemplos/miniconda/#creacion-de-ambiente-de-trabajo", "title": "Creaci\u00f3n de ambiente de trabajo", "text": "<ul> <li> <p>Desde el nodo de acceso, cargaremos el modulo de Miniconda.</p> <p><pre><code>module load miniconda/3.0\n</code></pre> - Crearemos el ambiente de conda sobre el cual trabajaremos.</p> <pre><code>conda create --name my-env\n</code></pre> </li> <li> <p>Si deseamaos crear un ambiente y a la vez instalar paquetes.</p> <pre><code>conda create --name my-env pytorch torchvision\n</code></pre> </li> </ul>"}, {"location": "guia-de-usuario/ejemplos/miniconda/#creacion-de-batch-script", "title": "Creaci\u00f3n de batch script", "text": "<p>En el script que creemos, deberemos especificar la cantidad de recursos que necesitamos. Luego deberemos cargar el m\u00f3dulo de Miniconda y activar nuestro ambiente de trabajo. Finalmente, escribiremos el comando necesario para ejecutar nuestro programa.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=app-test      # nombre del job\n#SBATCH --nodes=1                # cantidad de nodos\n#SBATCH --ntasks=1               # cantidad de tareas\n#SBATCH --cpus-per-task=1        # cpu-cores por task \n#SBATCH --mem=4G                 # memoria total por nodo\n#SBATCH --gres=gpu:1             # numero de gpus por nodo\n#SBATCH --time=00:05:00          # limite total de ejecucion\n\nmodule purge\nmodule load miniconda/3.0\nconda activate my-env\n\npython app-test.py\n\nconda deactivate\n</code></pre> <p>Si al momento de enviar su job obtienen el siguiente mensaje. </p> <pre><code>CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\nTo initialize your shell, run\n    $ conda init &lt;SHELL_NAME&gt;\nCurrently supported shells are:\n  - bash\n  - fish\n  - tcsh\n  - xonsh\n  - zsh\n  - powershell\nSee 'conda init --help' for more information and options.\nIMPORTANT: You may need to close and restart your shell after running 'conda init'.\n</code></pre> <p>Deberan adicionar  <code>eval \"$(conda shell.bash hook)\"</code> a su batch script luego de haber cargado el modulo de miniconda. Por lo tanto, el batch script resultante ser\u00e1 el siguiente. </p> <pre><code>#!/bin/bash\n#SBATCH --job-name=app-test      # nombre del job\n#SBATCH --nodes=1                # cantidad de nodos\n#SBATCH --ntasks=1               # cantidad de tareas\n#SBATCH --cpus-per-task=1        # cpu-cores por task \n#SBATCH --mem=4G                 # memoria total por nodo\n#SBATCH --gres=gpu:1             # numero de gpus por nodo\n#SBATCH --time=00:05:00          # limite total de ejecucion\n\nmodule purge\nmodule load miniconda/3.0\neval \"$(conda shell.bash hook)\"\nconda activate my-env\n\npython app-test.py\n\nconda deactivate\n</code></pre>"}, {"location": "guia-de-usuario/ejemplos/mpi-openmp/", "title": "MPI y OpenMP", "text": "<p>Para los siguientes dos ejemplos con OpenMP usaremos el siguiente c\u00f3digo  en C++ <code>prueba_openmp.cpp</code>.</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;omp.h&gt;\n\nvoid Hello(void); /* Thread function */\n\n/*--------------------------------------------------------------------*/\nint main(int argc, char* argv[]) {\n    int thread_count = strtol(argv[1], NULL, 10);\n    # pragma omp parallel num_threads(thread_count)\n        Hello();\n    return 0;\n}\n\n/* main */\n/*------------------------------------------------------------------- \n* * Function: Hello\n* * Purpose: Thread function that prints message\n* */\nvoid Hello(void) {\n    int my_rank = omp_get_thread_num();\n    int thread_count = omp_get_num_threads();\n    printf(\"Hello from thread %d of %d\\n\", my_rank, thread_count); /* Hello */\n}\n</code></pre> <p>Compilaremos el programa antes de crear y enviar el batch script.</p> <pre><code>module load gcc/5.5.0\ng++ prueba_openmp.cpp -fopenmp -lpthread -o prueba_openmp\nmodule unload gcc/5.5.0 \n</code></pre>"}, {"location": "guia-de-usuario/ejemplos/mpi-openmp/#openmp-de-un-solo-thread", "title": "OpenMP de un solo thread", "text": "<ol> <li>Crear el archivo <code>single_thread_openmp.sh</code>:</li> </ol> <pre><code>#!/bin/bash\n\n# Nombre del job:\n#SBATCH --job-name=single_thread_openmp\n\n# L\u00edmite de tiempo de 10 min:\n#SBATCH --time=10:00\n\n./prueba_openmp\n</code></pre> <ol> <li>Enviar a ejecutar el job:</li> </ol> <pre><code>sbatch single_thread_openmp.sh\n</code></pre>"}, {"location": "guia-de-usuario/ejemplos/mpi-openmp/#openmp-de-multiples-threads", "title": "OpenMP de m\u00faltiples threads", "text": "<ol> <li>Crear el archivo <code>multi_thread_openmp.sh</code>:</li> </ol> <pre><code>#!/bin/bash\n\n# Nombre del job:\n#SBATCH --job-name=multi_thread_omp_job\n# Nombre del archivo de salida:\n#SBATCH --output=multi_thread_omp_job.txt\n# Numero de tasks:\n#SBATCH --ntasks=1\n# Numero de CPUs por task:\n#SBATCH --cpus-per-task=4\n# L\u00edmite de tiempo de 10 min:\n#SBATCH --time=10:00\n\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n./prueba_openmp\n</code></pre> <ol> <li>Enviar a ejecutar el job:</li> </ol> <pre><code>sbatch multi_thread_openmp.sh\n</code></pre>"}, {"location": "guia-de-usuario/ejemplos/mpi-openmp/#mpi-multi-proceso", "title": "MPI multi-proceso", "text": "<p>Para el siguiente ejemplo usaremos el c\u00f3digo <code>prueba_mpi.c</code>:</p> <pre><code>#include &lt;mpi.h&gt;\n#include &lt;stdio.h&gt;\n\nint main(int argc, char** argv) {\n// Initialize the MPI environment\nMPI_Init(NULL, NULL);\n\n// Get the number of processes\nint world_size;\nMPI_Comm_size(MPI_COMM_WORLD, &amp;world_size);\n\n\n// Get the rank of the process\nint world_rank;\nMPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank);\n\n// Get the name of the processor\nchar processor_name[MPI_MAX_PROCESSOR_NAME];\nint name_len;\nMPI_Get_processor_name(processor_name, &amp;name_len);\n\n// Print off a hello world message\nprintf(\"Hello world from processor %s, rank %d out of %d processors\\n\",\nprocessor_name, world_rank, world_size);\n\n// Finalize the MPI environment.\nMPI_Finalize();\n}\n</code></pre> <ol> <li>Compilar el programa mpi:</li> </ol> <pre><code>module load mpich/4.0\nmpicc prueba_mpi.c -o prueba_mpi\nmodule unload mpich/4.0\n</code></pre> <ol> <li>Crear el archivo <code>multi_process_mpi.sh</code>:</li> </ol> <pre><code>#!/bin/bash\n\n# Nombre del job:\n#SBATCH -J prueba_mpi\n# Nombre de la partici\u00f3n:\n#SBATCH -p investigacion\n# N\u00famero de nodos:\n#SBATCH -N 2 \n# N\u00famero de tasks por nodo:\n#SBATCH --tasks-per-node=3 \n\n# Carga del modulo MPICH 4.0\nmodule load mpich/4.0\n# Ejecuci\u00f3n del compilado\nmpirun  prueba_mpi\n# Descarga del m\u00f3dulo\nmodule unload mpich/4.0\n</code></pre> <ol> <li>Enviar a ejecutar el job:</li> </ol> <pre><code>sbatch multi_process_mpi.sh\n</code></pre>"}, {"location": "guia-de-usuario/ejemplos/mpi-openmp/#mpi-y-openmp-a-la-vez-hibrido", "title": "MPI Y OpenMP a la vez (H\u00edbrido)", "text": "<p>Para este ejemplo usaremos el siguiente codigo hibrido y lo guardaremos en un archivo <code>hibrido.c</code>.</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;omp.h&gt;\n#include \"mpi.h\"\n\nint main(int argc, char *argv[]) {\n    int numprocs, rank, namelen;\n    char processor_name[MPI_MAX_PROCESSOR_NAME];\n    int iam = 0, np = 1;\n\n    MPI_Init(&amp;argc, &amp;argv);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;numprocs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Get_processor_name(processor_name, &amp;namelen);\n\n    #pragma omp parallel default(shared) private(iam, np)\n    {\n    np = omp_get_num_threads();\n    iam = omp_get_thread_num();\n    printf(\"Hello from thread %d out of %d from process %d out of %d on %s\\n\",\n            iam, np, rank, numprocs, processor_name);\n    }\n\n    MPI_Finalize();\n}\n</code></pre> <ol> <li>Compilar el programa h\u00edbrido:</li> </ol> <pre><code>module load mpich/4.0\nmpicc -fopenmp hibrido.c -o hibrido\nmodule unload mpich/4.0\n</code></pre> <ol> <li>Crear el archivo <code>hibrido_mpi_openmp.sh</code>:</li> </ol> <pre><code>#!/bin/bash\n\n# Un Job script para la ejecuci\u00f3n de un c\u00f3digo h\u00edbrido MPI-OpenMP\n\n#SBATCH --job-name=hibrido_mpi_openmp\n#SBATCH --output=hibrido_mpi_openmp.out\n#SBATCH --ntasks=4\n#SBATCH --cpus-per-task=8\n#SBATCH --partition=docencia\n\n# Cargar el modulo MPI.\nmodule load mpich/4.0\n\n# Configurar el valor de  OMP_NUM_THREADS con el numero de CPUs por task solicitado.\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n\n# Ejecutar el proceso con mpirun. Puede notar que no es necesario especificar el flag de MPI\n# '-n' puesto que automaticamente utiliza el valor de la configuraci\u00f3n de Slurm realizada\n\nmpirun ./hibrido\n\nmodule unload mpich/4.0\n</code></pre> <ol> <li>Enviar a ejecutar el job:</li> </ol> <pre><code>sbatch hibrido_mpi_openmp.sh\n</code></pre>"}, {"location": "guia-de-usuario/ejemplos/python/", "title": "Python", "text": "<p>Ejecuci\u00f3n del programa en Python, <code>prueba_python.py</code>:</p> <pre><code>from math import factorial as f\n\nprint(\"Hola mundo\")\nN = 100\nprint(\"%d! = %d\" %(N, f(N)))\n</code></pre> <ol> <li>Crear el archivo ej5.sh:</li> </ol> <pre><code>#!/bin/bash\n#SBATCH -J ej5 # nombre del job\n#SBATCH -p debug # nombre de la particion \n#SBATCH -c 1  # numero de cpu cores a usar\n\nmodule load python3/3.10.2 # carga el modulo de python version 3.10.2\npython3 prueba_python.py # siendo prueba_python.py el nombre del programa python\nmodule unload python3/3.10.2 \n</code></pre> <ol> <li>Enviar a ejecutar el job:</li> </ol> <pre><code>sbatch ej5.sh\n</code></pre>"}, {"location": "guia-de-usuario/enviar-jobs/", "title": "Sobre el env\u00edo de Jobs", "text": "<p>\u00a1El nodo de acceso no es para realizar c\u00f3mputos!</p> <p>Use Slurm para enviar sus cargas de trabajo a los diferentes nodos de c\u00f3mputo. </p> <p>Khipu es un recurso compartido por m\u00faltiples usuarios al mismo tiempo. Para asignar y gestionar los recursos de manera justa hacemos uso del gestor de trabajos Slurm. A trav\u00e9s de Slurm los usuarios puede enviar, cancelar y revisar sus cargas de trabajo o jobs a los diferentes nodos de c\u00f3mputo disponibles.</p> <p>Los jobs pueden ser ejecutados de dos maneras distintas:</p> <ol> <li> <p>Modo batch: permite enviar un script que contiene todo lo necesario para la ejecuci\u00f3n de su job. El cual se ejecutar\u00e1 de manera ininterrupida por el perido de tiempo asignado en el script y permitido a su tipo de cuenta. De esta manera usted manda a ejecutar su carga de trabajo y no tiene la necesitar de mantenerse conectado a Khipu para que continue su ejecuci\u00f3n. La salida de su job ser\u00e1 escrita de manera continua en un archivo, el cual usted puede consultar multiples veces para ver el avance de su trabajo hasta su finalizaci\u00f3n. </p> </li> <li> <p>Modo interactivo: permite a los usuarios interactuar con su job en ejecuci\u00f3n de manera directa a trav\u00e9s de la l\u00ednea de comandos. Este modo es similar a reservar recursos en una nodo, conectarte a \u00e9l y luego de manera manual (interactiva) ejecutar cada unos de los comandos que requiera para completar su trabajo. Sin embargo, si su conexi\u00f3n con el nodo es interrupida o deja de tener actividad, su job ser\u00e1 terminado. Este tipo de jobs es ideal para cargas de trabajo peque\u00f1as, preparar o realizar peque\u00f1as pruebas de la ejecuci\u00f3n de jobs m\u00e1s largos o realizar labores de debugging. </p> </li> </ol> <p>Los jobs que env\u00ede a trav\u00e9s de Slurm ser\u00e1n puestos en ejecuci\u00f3n dependiendo de su tipo de cuenta y la cantidad de recursos solicitados (n\u00facleos CPU, memor\u00eda RAM o  GPU). Generalmente, los jobs con pedidos de recursos m\u00e1s modestos y acotados suelen esperar menos tiempo en la fila de Slurm. Si desconoce la cantidad de recursos que su job demandar\u00e1 puede usar las particiones <code>debug</code> o <code>debug-gpu</code> para realizar pruebas antes de enviar sus jobs a otras particiones m\u00e1s demandadas. </p>"}, {"location": "guia-de-usuario/enviar-jobs/#uso-del-nodo-de-acceso", "title": "Uso del nodo de acceso", "text": "<p>El nodo de acceso es compartido por todos los usuarios y, como su nombre lo indica, debe ser usado para el acceso al cluster y la ejecuci\u00f3n de tareas administrativas como:</p> <ul> <li>Compilaci\u00f3n de c\u00f3digo. </li> <li>Descarga de archivos. El nodo de acceso es el \u00fanico nodo con salida a internet.</li> <li>Creaci\u00f3n de ambientes de trabajo (<code>virtualenv</code>) e instalaci\u00f3n de paquetes de Python</li> <li>Env\u00edo y manejo de jobs </li> <li>Transferencia de archivos </li> <li>Peque\u00f1as tareas de pre y post-procesamiento que no demanden de uso alto de recursos en CPU y RAM.</li> </ul> <p>Todas las tareas que no se ajusten a las indicaciones dadas sobre el uso del nodo de acceso ser\u00e1n canceladas sin previo aviso y el usuario responsable ser\u00e1 sancionado de acuerdo a nuestra pol\u00edtica de uso. </p>"}, {"location": "guia-de-usuario/enviar-jobs/comandos-basicos/", "title": "Comandos b\u00e1sicos de SLURM", "text": "<p>En esta gu\u00eda se van a desarrollar algunos comandos b\u00e1sicos de Slurm. Si es su primera vez usando Slurm, le ser\u00e1 de mucha utilidad acompa\u00f1ar esta lectura realizando pruebas de los comandos mencionados en el cluster. Al inicio puede resultar un poco tedioso escribir nuestras cargas de trabajo en scripts, sin embargo poco a poco le resultar\u00e1 m\u00e1s sencillo y a la larga usted manejar\u00e1 una herramiento valiosa y ampliamente usada en el mundo del HPC.</p> <p>Los principales comandos de Slurm se muestran en la siguiente tabla:</p> Comando Descripci\u00f3n <code>sbatch</code>   Env\u00eda un batch script <code>srun</code>  Ejecuta un job paralelo (step) <code>squeue</code>  Muestra informaci\u00f3n de la cola de trabajos <code>scancel</code>  Env\u00eda un signal o cancela un job, array de jobs o job steps. <code>sinfo</code>  Muestra informaci\u00f3n de las particiones."}, {"location": "guia-de-usuario/enviar-jobs/comandos-basicos/#creacion-de-un-batch-script", "title": "Creaci\u00f3n de un batch script", "text": "<p>Un batch script es un archivo que indica los recursos necesarios y los pasos a seguir para la ejecuci\u00f3n de un determinado job. A continuaci\u00f3n se muestra un ejemplo:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=nombre_del_job\n#SBATCH --partition=debug\n#SBATCH --ntasks=1 --cpus-per-task=4\n#SBATCH --mem=4G\n#SBATCH --time=00:10:00\n#SBATCH --output=nombre_archivo.out\n#SBATCH --error=nombre_archivo.err\n#SBATCH --mail-type=END,FAIL\n#SBATCH --mail-user=user@example.com\n\n## Especificar el directorio de trabajo\ncd &lt;mi-directorio-de-trabajo&gt;\n\n## Cargar los m\u00f3dulos necesarios\nml load &lt;module&gt;/&lt;version&gt;\n\n## Ejecute su programa\nsrun &lt;mi-programa&gt;\n</code></pre> <p>En este ejemplo <code>#!/bin/bash</code> indica que debe ser interpretado como un script de bash. Las siguientes l\u00edneas que contienen <code>#SBATCH</code> son directivas que especifican determinadas opciones disponibles en Slurm usando la siguiente sintaxis:</p> <pre><code>#SBATCH &lt;opci\u00f3n&gt;=&lt;valor&gt;\n</code></pre> <p>Por ejemplo, la l\u00ednea 3 <code>#SBATCH --job-name=nombre_del_job</code> indica cual es el nombre del job. </p> <p>La l\u00ednea 4, especifica que el job se ejecutar\u00e1 en la partici\u00f3n <code>debug</code>. </p> <p>Las l\u00ednea 5 y 6, especifican los recursos computacionales que ser\u00e1n usados para la ejecuci\u00f3n del job. En este ejemplo, <code>--ntasks</code> indica que se ejecutar\u00e1 un proceso, <code>--cpus-per-task</code> que se usar\u00e1n 4 n\u00facleos CPU por cada proceso y <code>--mem</code> que se utilizar\u00e1 4GB de RAM en total. </p> <p>La l\u00ednea 7 indica que el l\u00edmite m\u00e1ximo de duraci\u00f3n del job ser\u00e1 de 10 minutos. Si el job pasa de esa duraci\u00f3n, ser\u00e1 cancelado. </p> <p>Las l\u00edneas 8 y 9 indican donde se escribir\u00e1n la salida estandar <code>--output</code> y la salida en caso de error <code>--error</code>. Si no se indican, tomaran un valor por defecto adicionado al identificador del job.</p> <p>La l\u00ednea 10 indica que se env\u00ede un mail cuando el job llegue a los estados de <code>END</code> (culminaci\u00f3n normal) o <code>FAIL</code> (culminaci\u00f3n por error).</p> <p>La l\u00ednea 14 especifica el directorio de trabajo donde se encuentra el programa que ser\u00e1 ejecutado. Si no lo especifica, usar\u00e1 el directorio desde donde est\u00e9 enviando el job. Es altamente recomendado especificar su directorio de trabajo.</p> <p>La l\u00ednea 17 indica cuales [m\u00f3dulos][modulos] deber\u00e1n ser cargados para la ejecuci\u00f3n del job.</p> <p>Finalmente, la l\u00ednea 20 indica cual ser\u00e1 el comando que ser\u00e1 ejecutado. Es importante anteponer <code>srun</code> antes del comando que ejecutar\u00e1. Por ejemplo: <code>srun python3 myapp.py</code> o <code>srun ./myapp</code>. </p>"}, {"location": "guia-de-usuario/enviar-jobs/comandos-basicos/#envio-de-un-batch-job", "title": "Env\u00edo de un batch job", "text": "<p>Para enviar el job script que se cre\u00f3 en el paso anterior deberemos usar el comando <code>sbatch</code>, el cual posee la siguiente sintaxis:</p> <pre><code> sbatch [opciones] nombre-de-mi-job.slurm [argumentos del job ...]\n</code></pre> <p>Donde las <code>[opciones]</code> tienen las mismas estructura que aquellas que escribimos en el batch script, pero sin la palabra <code>#SBATCH</code>. Aquellas opciones que especifiquemos al momento de ejecutar <code>sbatch</code> tiene precedencia por sobre aquellas que se encuentren dentro del script. Por ejemplo, si yo ejecuto <code>sbatch --partition=standard mi-scrip.slurm</code>, donde <code>mi-script.slurm</code> es el batch script anterior, el job se ejecutar\u00e1 en la partici\u00f3n <code>standard</code> en lugar de <code>debug</code> que fue especificada dentro del job. No siempre ser\u00e1 necesario sobreescribir las opciones que se encuentran dentro del script. Para la mayor\u00eda de casos bastar\u00e1 con ejecutar:</p> <pre><code>sbatch nombre-de-mi-job.slurm\n</code></pre> <p>Si bien no hay una restricci\u00f3n en la extensi\u00f3n que debe de tener nuestro batch script, es una buena paractica usar la extension <code>*.slurm</code> para diferenciarlo de los bash script <code>*.sh</code> tradicionales. </p>"}, {"location": "guia-de-usuario/enviar-jobs/comandos-basicos/#examinar-la-cola-de-ejecucion", "title": "Examinar la cola de ejecuci\u00f3n", "text": "<p>Cuando usted env\u00eda su job, no necesariamente se ejecutar\u00e1 de manera inmediata. Este puede estar en espera por un tiempo hasta que se liberen los recursos necesarios para que pueda entrar a ejecuci\u00f3n. Para ver los jobs que se encuentran en espera y en ejecuci\u00f3n usaremos el comando <code>squeue</code>.</p> <pre><code>squeue\n</code></pre> <p>El cual nos mostrar\u00e1 un resultado parecido al siguiente:</p> <pre><code>   JOBID PARTITION    NAME     USER   ST   TIME  NODES NODELIST(REASON)\n   5757       gpu pretrain some-user  PD   0:00      5 (PartitionNodeLimit)\n   5758  standard     bash some-user  PD   0:00      1 (QOSMaxWallDurationPerJobLimit)\n   5741       gpu fn_somet some-user  R    1:17:21   1 g001\n</code></pre> <p>Aqu\u00ed podemos notar que hay tres jobs, de los cuales uno se encuentra en ejecuci\u00f3n (por eso tienen la <code>R</code> de running) y otro dos se encuentra pendientes <code>PD</code>. Es importante visualizar que los jobs en pendiente tienen en el apartado de NODELIST(REASON), una explicaci\u00f3n r\u00e1pida de por qu\u00e9 se encuentra en ese estado. En este ejemplo, <code>(PartitionNodeLimit)</code> me indica que estoy tratando de reservar m\u00e1s nodos de los permitidos en esa partici\u00f3n y <code>(QOSMaxWallDurationPerJobLimit)</code> que estoy tratando de reservar m\u00e1s tiempo del permitido por cada job.</p> <p>En algunos casos desearemos solamente visualizar el estado de nuestros jobs. Para ello ejecutaremos:</p> <pre><code>squeue --me\n</code></pre>"}, {"location": "guia-de-usuario/enviar-jobs/comandos-basicos/#cancelar-trabajos", "title": "Cancelar trabajos", "text": "<p>En algunos casos necesitaremos cancelar nuestro job porque tal vez falt\u00f3 a\u00f1adir algo, o no est\u00e1 ejecutando como esperamos. En sos casos bastar\u00e1 con ejecutar el comando <code>scancel</code> acompa\u00f1ado del id del job:</p> <p><pre><code>scancel &lt;job-id&gt;\n</code></pre> El identificador del job puede obtenerse mirando la cola de ejecuci\u00f3n con <code>squeue</code>.</p>"}, {"location": "guia-de-usuario/enviar-jobs/comandos-basicos/#ver-informacion-sobre-los-nodos-y-particiones", "title": "Ver informaci\u00f3n sobre los nodos y particiones", "text": "<p>Para obtener informaci\u00f3n sobre las particiones, su estado y nodos disponibles ejecutaremos  el comando <code>sinfo</code>. El cual nos mostrar\u00e1 en patalla una salida similar a la siguiente:</p> <pre><code>PARTITION    AVAIL  TIMELIMIT  NODES  STATE NODELIST\ndebug*          up   infinite      1   idle n003\ndebug-gpu       up   infinite      1    mix g001\nstandard        up   infinite      4   idle n[003-006]\nbig-mem         up   infinite      3   idle ag001,g002,n006\ngpu             up   infinite      1    mix g001\ngpu             up   infinite      2   idle ag001,g002\ndata-science    up   infinite      1   down ds001\n</code></pre> <p>Ah\u00ed podemos ver que algunos nodos/particiones se encuentran sin uso <code>\u00ecdle</code>, mientras que otras poseen algunos nodos en uso y otros en desuso <code>mix</code>, o se encuentran ca\u00eddos <code>down</code>. Los nodos pueden encontrarse ca\u00eddos por errores en su funcionamiento, fallas en la conectividad o por la realizaci\u00f3n de trabajos de mantenimiento. Si desea obtener mayores detalles del porqu\u00e9 del estado de un nodo ca\u00eddo, puede ejecutar el comando <code>sinfo -R</code>. El cual nos mostrar\u00e1 en patalla una salida similar a la siguiente:</p> <pre><code>REASON               USER      TIMESTAMP           NODELIST\nMantenimiento progra root      2025-05-05T17:56:50 ds001\n</code></pre> <p>En este caso podemos observar que el motivo de la ca\u00edda del nodo es debido a unos trabajos de manteniento.</p>"}, {"location": "guia-de-usuario/enviar-jobs/comandos-basicos/#bonus-obtener-detalles-de-un-job", "title": "Bonus: Obtener detalles de un job", "text": "<p>En algunas ocasiones, olvidamos detalles del job que estamos ejecutando o que se encuentra por ejecutar. En esos casos podemos usar el comando <code>scontrol show job &lt;job-id&gt;</code> para obtener mayor informaci\u00f3n sobre ese job. </p> <p>Por ejemplo, si quiero ver detalles del job <code>1077</code> ejecutar\u00e9:</p> <pre><code>scontrol show job 1077\n</code></pre> <p>Y obtendr\u00e9 una respuesta en pantalla parecida a la siguiente:</p> <pre><code>JobId=1077 JobName=CudaJob\n   UserId=alan.turing(1000) GroupId=alan.turing(1000) MCS_label=N/A\n   Priority=1683 Nice=0 Account=pregrado QOS=a-pregrado\n   JobState=COMPLETED Reason=None Dependency=(null)\n   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n   RunTime=00:00:02 TimeLimit=00:10:00 TimeMin=N/A\n   SubmitTime=2024-11-06T02:41:48 EligibleTime=2024-11-06T02:41:48\n   AccrueTime=2024-11-06T02:41:48\n   StartTime=2024-11-06T02:41:48 EndTime=2024-11-06T02:41:50 Deadline=N/A\n   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2024-11-06T02:41:48 Scheduler=Main\n   Partition=debug AllocNode:Sid=khipu:2943597\n   ReqNodeList=(null) ExcNodeList=(null)\n   NodeList=n005\n   BatchHost=n005\n   NumNodes=1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\n   ReqTRES=cpu=1,mem=100M,node=1,billing=1\n   AllocTRES=cpu=1,mem=100M,node=1,billing=1\n   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\n   MinCPUsNode=1 MinMemoryCPU=100M MinTmpDiskNode=0\n   Features=(null) DelayBoot=00:00:00\n   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\n   Command=/home/alan.turing/gpu_job_shard.sh\n   WorkDir=/home/alan.turing\n   StdErr=/home/alan.turing/slurm-1077.out\n   StdIn=/dev/null\n   StdOut=/home/alan.turing/slurm-1077.out\n   Power=\n</code></pre>"}, {"location": "guia-de-usuario/enviar-jobs/jobs-interactivos/", "title": "Jobs Intercativos", "text": "<p>Para iniciar un job de manera interactiva deber\u00e1 ejecutar el comando <code>srun</code> usando la siguiente sintaxis:</p> <p><pre><code>srun [recursos] --pty /bin/bash\n</code></pre> Por defecto todos los jobs interactivos tienen una duraci\u00f3n l\u00edmite de 30 minutos. Usted puede modificar los recursos a reservarse y el tiempo l\u00edmite de duraci\u00f3n modificando <code>[recursos]</code> con los flags listados aqu\u00ed. </p> <p>Por ejemplo:</p> <ul> <li>Si desea solicitar 4 cores y 4GB RAM en la partici\u00f3n <code>standard</code>.</li> </ul> <pre><code>srun -c 4 --mem=4GB -p standard --pty /bin/bash\n</code></pre> <ul> <li>Si desea solicitar 1 shard GPU en la partici\u00f3n <code>debug-gpu</code>.</li> </ul> <pre><code>srun --gres=shard:1 -p debug-gpu --pty /bin/bash\n</code></pre> <p>!!! warning Mant\u00e9ngase conectado mientras usa jobs interactivos     Si usted pierde conexi\u00f3n, deja de tener actividad o sale de su sesi\u00f3n, perder\u00e1 acceso a su job interactivo. Para mitigar la cancelaci\u00f3n de su job por inactividad puede usar el comando <code>screen</code>. Sin embargo, \u00faselo de manera razonable ya que usted estar\u00e1 manteniendo en reserva recursos que no est\u00e1 usando.</p>"}, {"location": "guia-de-usuario/enviar-jobs/monitorear/", "title": "Monitoreo de jobs", "text": "<p>Recomendaci\u00f3n General</p> <p>Aseg\u00farese de reservar la cantidad de RAM y CPUs necesarios para la ejecuci\u00f3n de su job. No reserve recursos que no necesita, ya que de hacerlo, perjudicar\u00e1 la ejecuci\u00f3n de los dem\u00e1s usuarios del cluster. </p> <p>A continuaci\u00f3n se muestran algunos ejemplos de como medir el uso de CPU y RAM de su job a fin de que pueda refinar la reserva de recursos.  </p>"}, {"location": "guia-de-usuario/enviar-jobs/monitorear/#jobs-en-ejecucion", "title": "Jobs en ejecuci\u00f3n", "text": "<p>Si su job se encuentra en ejecuci\u00f3n, usted puede revisar su uso actual de recursos. Sin embargo, deber\u00e1 esperar hasta su finalizaci\u00f3n para ver el uso m\u00e1ximo de recursos durante toda su ejecuci\u00f3n. </p> <p>La manera m\u00e1s sencilla de revisar el uso instant\u00e1neo de recursos es hacer crear un job interactivo en el nodo de computaci\u00f3n donde su job se encuentra ejecut\u00e1ndose. Para saber en que nodo debe crear el job interactivo, ejecute:</p> <p><pre><code>squeue --me\n</code></pre> El cual nos da como salida:  <pre><code>JOBID PARTITION     NAME     USER  ST       TIME  NODES NODELIST(REASON)\n21615 standard    bert-sar juan   PD       0:00      1 n003\n</code></pre></p> <p>En ella podemos notar que su job bert-sar se encuentra ejecutandose en el nodo <code>n003</code> de la parici\u00f3n <code>standard</code>. Con esa informaci\u00f3n crearemos el job interactivo.</p> <pre><code>srun --pty -t 02:00 --mem=1G -p standard --nodelist=n003 bash\n</code></pre> <p>Una vez dentro del nodo de c\u00f3mputo, ejecutaremos <code>ps</code> o <code>htop</code>.</p> <ul> <li> <p><code>ps</code> le brindar\u00e1 la informaci\u00f3n instant\u00e1nea del uso de recursos cada vez que ejecute el comando. </p> <pre><code>[alan.turing@n004 ~]$ ps -u$USER -o %cpu,rss,args\n%CPU   RSS COMMAND\n0.0  2376 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n0.0  2380 python triangle.py\n</code></pre> <p>El reporte de memoria de <code>ps</code> se muestra en KB, podemos notar que los procesos listados consumen alrededor de 2000 KB de RAM y que el uso de los CPUs es casi nulo.</p> </li> <li> <p><code>htop</code> se ejecuta de manera interactiva y muestra las estad\u00edsticas de uso en vivo. Puede presionar la tecla <code>u</code>, ingresar su nombre de usuario y luego <code>enter</code> para filtrar solo sus procesos. La informaci\u00f3n del uso de memoria, se encuentra en la columna RES. Para solicitar ayuda puede presionar <code>?</code> y si desea salir <code>q</code> .</p> </li> </ul> <p></p>"}, {"location": "guia-de-usuario/enviar-jobs/monitorear/#jobs-finalizados", "title": "Jobs finalizados", "text": "<p>Slurm guarda las estad\u00edsticas de cada job, inclu\u00eddo cuanta memoria y CPU fue utilizada.</p>"}, {"location": "guia-de-usuario/enviar-jobs/monitorear/#sacct", "title": "sacct", "text": "<p>Tambi\u00e9n se puede usar <code>sacct</code> para obtener la informaci\u00f3n del job. Lamentablemente, el output por defecto de <code>sacct</code> no es del todo entendible, por ello se recomienda procesar la salida de la siguiente manera. </p> <pre><code>[alan.turing@khipu ~]$ export SACCT_FORMAT=\"JobID%20,JobName,User,Partition,NodeList,Elapsed,State,ExitCode,MaxRSS,AllocTRES%32\"\n[alan.turing@khipu ~]$ sacct -j 21886\n     JobID    JobName      User  Partition        NodeList    Elapsed      State ExitCode     MaxRSS                        AllocTRES \n---------- ---------- --------- ---------- --------------- ---------- ---------- -------- ---------- -------------------------------- \n      1063 simple_ex+   alan.tur+      debug            n005   00:00:11  COMPLETED      0:0             billing=2,cpu=2,mem=200M,node=1 \n1063.batch      batch                                 n005   00:00:11  COMPLETED      0:0                       cpu=2,mem=200M,node=1 \n</code></pre>"}, {"location": "guia-de-usuario/enviar-jobs/opciones-de-slurm/", "title": "Opciones m\u00e1s comunes de Slurm", "text": "<p>A continuaci\u00f3n se listan algunas de las opciones m\u00e1s comunes al momento de enviar jobs usando Slurm. Notaremos que existe una opci\u00f3n larga y otra corta para referirnos al mismo par\u00e1metro.</p>"}, {"location": "guia-de-usuario/enviar-jobs/opciones-de-slurm/#opciones-basicas-del-job", "title": "Opciones ba\u015bicas del job", "text": "Opci\u00f3n Larga Opci\u00f3n Corta Descripci\u00f3n Ejemplo <code>--job-name</code> <code>-J</code> Establece un nombre para el trabajo. <code>--job-name=miTrabajo</code> <code>--partition</code> <code>-p</code> Especifica la partici\u00f3n a la que se enviar\u00e1 el trabajo. <code>--partition=debug</code> <code>--time</code> <code>-t</code> Establece un l\u00edmite de tiempo para el trabajo. Formato: <code>d\u00edas-horas:minutos:segundos</code>. <code>--time=01:30:00</code> <code>--output</code> <code>-o</code> Indica el nombre del archivo donde se guadar\u00e1 la salida <code>stdout</code> <code>--output=salida-del-job.out</code> <code>--error</code> <code>-e</code> Indica el nombre del archivo donde se guadar\u00e1 la salida <code>stderr</code> <code>--error=errores-del-job.err</code> <p>Si no se establecen valores para <code>--output</code> y/o <code>--error</code> se crear\u00e1n archivos con el siguiente patr\u00f3n <code>slurm-%j.out</code> donde <code>%j%</code> es el id del job.</p>"}, {"location": "guia-de-usuario/enviar-jobs/opciones-de-slurm/#opciones-para-la-distribucion-de-tareas", "title": "Opciones para la distribuci\u00f3n de tareas", "text": "Opci\u00f3n Larga Opci\u00f3n Corta Descripci\u00f3n Ejemplo <code>--nodes</code> <code>-N</code> N\u00famero de nodos a asignar para el trabajo. <code>--nodes=2</code> <code>--ntasks</code> <code>-n</code> N\u00famero de tareas a lanzar. <code>--ntasks=4</code> <code>--ntasks-per-node</code> N\u00famero de tareas por nodo. <code>--ntasks-per-node=3</code>"}, {"location": "guia-de-usuario/enviar-jobs/opciones-de-slurm/#opciones-para-la-solicitud-de-cpu", "title": "Opciones para la solicitud de CPU", "text": "Opci\u00f3n Descripci\u00f3n Ejemplo <code>--cpus-per-task</code> Indica el n\u00famero de cores por tarea <code>--cpus-per-task=3</code>"}, {"location": "guia-de-usuario/enviar-jobs/opciones-de-slurm/#opciones-para-la-solicitud-de-memoria-ram", "title": "Opciones para la solicitud de memoria RAM", "text": "Opci\u00f3n Descripci\u00f3n Ejemplo <code>--mem</code> Establece la memoria requerida por nodo. <code>--mem=4G</code> <code>--mem-per-cpu</code> Establece la m\u00ednima memoria requerida por cada n\u00facleo CPU. <code>--mem-per-cpu=200M</code> <code>--mem-per-gpu</code> Establece la m\u00ednima memoria requerida por cada GPU reservado. <code>--mem-per-gpu=2G</code> <p>Para la memoria RAM la unidad por defecto son los MB y pueden usarse <code>[K|M|G|T]</code> como sufijos para expresar las unidades de memor\u00eda. Por ejemplo: 100K son 100 Kilobytes,y 10G son 10 gibabytes.</p>"}, {"location": "guia-de-usuario/enviar-jobs/opciones-de-slurm/#opciones-para-la-solicitud-de-gpu", "title": "Opciones para la solicitud de GPU", "text": "Opci\u00f3n Descripci\u00f3n Ejemplo <code>--gres=shard:&lt;numero&gt;</code> Establece la cantidad de GPU shards a usar. Permite el uso compartido de GPU (Recomendado). <code>--gres=shard:1</code> <code>--gres=gpu:&lt;numero&gt;</code> Establece la cantidad de GPUs para uso exclusivo. <code>--gres=gpu:1</code> <p>En ambas opciones es posible adicionar el tipo de GPU que se desea reservar <code>--gres=&lt;recurso&gt;:&lt;tipo&gt;:&lt;cantidad&gt;</code>. Actualmente se dispone de los siguientes tipos de GPU: <code>tesla</code>, <code>a100</code> y <code>rtxa6000</code>. Usando cualquiera de estas opciones, los ejemplos anteriores podr\u00edan variar a <code>--gres=shard:a100:1</code> o <code>--gres=gpu:tesla:1</code>. </p>"}, {"location": "guia-de-usuario/enviar-jobs/opciones-de-slurm/#opciones-para-el-envio-de-mails", "title": "Opciones para el env\u00edo de mails", "text": "<p>Es posible habilitar las notificaciones por correo electr\u00f3nico cada vez que ocurra un determinado evento como el inicio de un job o su falla. Esta opci\u00f3n es bastante \u00fatil ya que permite conocer el estado del job sin la necesidad de estar revisando constantemente la cola de ejecuci\u00f3n. Utilice la opci\u00f3n <code>ALL</code> para recibir notificaciones al iniciar y terminar un job. Opciones disponibles <code>ALL</code>, <code>BEGIN</code>, <code>END</code>, <code>FAIL</code>, <code>NONE</code></p> Opci\u00f3n Descripci\u00f3n Ejemplo <code>--mail-type</code> Env\u00eda un mail cada vez que ocurra un determinado evento. <code>--mail-type=END,FAIL</code> <code>--mail-user</code> Establece el mail al cual se enviar\u00e1n las notificaciones. <code>--mail-user=&lt;mi-coreo-electronico&gt;</code>"}, {"location": "guia-de-usuario/enviar-jobs/particiones/", "title": "Particiones", "text": "<p>Las particiones son grupos de nodos que tienen caracter\u00edsticas similares y que comparten un mismo conjunto de restricciones.</p> <p>Las particiones permiten organizar los recursos disponibles y gestionar de manera eficiente c\u00f3mo se asignan las tareas o trabajos. Khipu posee seis diferentes particiones en Slurm.</p> Nombre de partici\u00f3n Descripci\u00f3n debug partici\u00f3n para probar ejecuciones peque\u00f1as en CPU con prop\u00f3sitos de debugging debug-gpu partici\u00f3n para probar ejecuciones peque\u00f1as en GPU con prop\u00f3sitos de debugging standard partici\u00f3n de uso general en CPU big-mem partici\u00f3n de uso general en CPU con gran cantidad de memoria gpu partici\u00f3n de uso general en GPU data-science partici\u00f3n de Ciencia de Datos <p>El n\u00famero de jobs y la cantidad de recursos que pueden ser reservados depender\u00e1 de la partici\u00f3n seleccionada y su tipo de usuario. Para listar las particiones que se encuentran disponibles para su usuario, ejecute el comando:</p> <pre><code>sinfo -O \"partition\"     \n</code></pre>"}, {"location": "guia-de-usuario/enviar-jobs/particiones/#detalles-de-las-particiones", "title": "Detalles de las particiones", "text": "<p>A continuaci\u00f3n se listan las particiones existentes y el detalle de cada una de ellas.</p> Partici\u00f3n Nodos Total de Cores Total de Memoria RAM (GB) Total shards de GPU M\u00e1x duraci\u00f3n del Job (min) debug n003 32 160 - 30 debug-gpu g001 32 160 32 30 standard n00[3-6] 144 1385 - depende del tipo de usuario big-mem g002, ds001, ag001 224 3095 - depende del tipo de usuario gpu g00[1-2], ag001 208 2224 208 depende del tipo de usuario data-science ds001 96 1031 96 depende del tipo de usuario"}, {"location": "guia-de-usuario/enviar-jobs/particiones/#debug", "title": "debug", "text": "<p>Tiempos de espera m\u00e1s cortos y tiempo de ejecuci\u00f3n peque\u00f1o. Utilice esta partici\u00f3n para probar la ejecuci\u00f3n de su job antes de enviarlo a una partici\u00f3n de m\u00e1s recursos.</p>"}, {"location": "guia-de-usuario/enviar-jobs/particiones/#debug-gpu", "title": "debug-gpu", "text": "<p>Tiempos de espera m\u00e1s cortos y tiempo de ejecuci\u00f3n peque\u00f1o. Utilice esta partici\u00f3n para probar la ejecuci\u00f3n de su job en GPU antes de enviarlo a una partici\u00f3n de m\u00e1s recursos.</p>"}, {"location": "guia-de-usuario/enviar-jobs/particiones/#standard", "title": "standard", "text": "<p>Partici\u00f3n de uso general para tareas que requieren cores de CPU. Utilice esta partici\u00f3n para ejecutar tareas intensas en uso de CPU. Los tiempos de espera en cola depender\u00e1n de la cantidad de usuarios que se encuentren usando la partici\u00f3n. Procure dimensionar correctamente su trabajo para disminuir su tiempo de espera en la cola. Use la partici\u00f3n <code>debug</code> para dicho prop\u00f3sito.</p>"}, {"location": "guia-de-usuario/enviar-jobs/particiones/#big-mem", "title": "big-mem", "text": "<p>Partici\u00f3n de uso general para tareas que requieren cores de CPU y gran cantidad de memoria RAM. Utilice esta partici\u00f3n para ejecutar tareas intensas en memoria. Los tiempos de espera en cola depender\u00e1n de la cantidad de usuarios que se encuentren usando la partici\u00f3n. Procure dimensionar correctamente su trabajo para disminuir su tiempo de espera en la cola. Use la partici\u00f3n <code>debug</code> para dicho prop\u00f3sito.</p>"}, {"location": "guia-de-usuario/enviar-jobs/particiones/#gpu", "title": "gpu", "text": "<p>Partici\u00f3n de uso general para tareas que requieren cores de GPU. Es una de las particiones de mayor demanda en Khipu, es por ello que no es posible reservar GPUs de manera exclusiva. El uso de la GPU es compartido a traves de sharding. Los tiempos de espera en cola depender\u00e1n de la cantidad de usuarios que se encuentren usando la partici\u00f3n. Procure dimensionar correctamente su trabajo para disminuir su tiempo de espera en la cola. Use la partici\u00f3n <code>debug-gpu</code> para dicho prop\u00f3sito.</p>"}, {"location": "guia-de-usuario/enviar-jobs/particiones/#data-science", "title": "data-science", "text": "<p>Partici\u00f3n de uso general, pero con acceso priorizado para los miembros de la facultad de Ciencia de Datos. Dentro de esta partici\u00f3n se encuentra el nodo <code>ds001</code>, el \u00fanico nodo de c\u00f3mputo con acceso a internet. Cuenta con una tarjeta GPU compartida a trav\u00e9s de sharding. </p>"}, {"location": "guia-de-usuario/software/", "title": "Software", "text": ""}, {"location": "guia-de-usuario/software/#modulos", "title": "M\u00f3dulos", "text": "<p>Los sofwares disponibles se realizan a traves de sotfware modules. Esto nos permite contar con diferentes versiones del mismo software sin mayores conflictos.  Los m\u00f3dulos ayudan a cambiar entre diferentes aplicaciones y sus versiones con relativa facilidad, especialmente en ambientes compartidos. Puede encontrar la lista de software disponible aqu\u00ed.</p>"}, {"location": "guia-de-usuario/software/#pedidos-de-instalacion", "title": "Pedidos de instalaci\u00f3n", "text": "<p>Si el software que necesita no se encuentra en la lista de software disponible, y usted tiene problemas para instalarlo de manera local, por favor genere un ticket en Mesa de Ayuda brindando la mayor cantidad de detalles posibles sobre el software que necesita. Si el software es licenciado, incluya en enlace a la web del proveedor y su respectiva licencia. </p>"}, {"location": "guia-de-usuario/software/instalacion/", "title": "Instalaci\u00f3n de Software", "text": "<p>El siguiente documento describe como instalar software en Khipu para un proyecto o curso. Antes de realizar una instalaci\u00f3n, por favor revise si el software ya se encuentra disponible como m\u00f3dulo con el comando <code>module avail</code> o <code>ml av</code>.</p>"}, {"location": "guia-de-usuario/software/instalacion/#requisitos-para-instalar-software", "title": "Requisitos para instalar software", "text": "<ul> <li>En caso de software licenciado, el usuario debe proveer la licencia y/o instalador del software al administrador para ser instalado. </li> <li>El usuario puede instalar el software y libraries necesarios en su <code>/home/&lt;username&gt;/</code>, en caso de no requerir licencia o ser de c\u00f3digo abierto. </li> <li>El usuario puede compilar en el nodo l\u00edder antes de enviar un job a ejecutar. No enviar jobs de compilaci\u00f3n a la fila del cluster. </li> <li>Siendo Khipu un cluster enfocado al procesamiento y HPC; no se instalar\u00e1n bases de datos, containers o m\u00e1quinas virtuales. </li> <li>Si el software o library requiere permisos especiales para instalaci\u00f3n, solamente el profesor encargado del curso o un investigador de proyecto pueden solicitar la instalaci\u00f3n bajo coordinaci\u00f3n con el administrador. </li> </ul> <ul> <li>Si el software que planea instalar posee dependencias como librer\u00edas, interfaces o m\u00f3dulos; revise primero si ya se encuentran disponibles en el cluster antes de instalarlas por su cuenta. </li> </ul> <p>Para entrar en contacto con el administrador del cluster, por favor enviar un mensaje a khipu@utec.edu.pe.</p>"}, {"location": "guia-de-usuario/software/instalacion/#proceso-de-instalacion", "title": "Proceso de instalaci\u00f3n", "text": "<p>Tal como se mencion\u00f3 anteriormente, usted puede instalar software libre o que no requiere licencia en su espacio personal de trabajo. Sin embargo, antes de proceder con la instalaci\u00f3n aseg\u00farese que dicho software no requiere permisos root para ser instalado. Una vez echo esto, usted deber\u00e1 moverse al directorio en el cual planea realizar la instalaci\u00f3n y seguir las instrucciones del proveedor del software que planea instalar. </p> <p>Por lo general, los pasos son similares, es por ello que a continuaci\u00f3n se muestra un ejemplo realizando la instalaci\u00f3n de la librer\u00eda Zlib, un software usado para comprimir y descomprimir data.</p> <ul> <li>Creamos un directorio en el cual almacenaremos los c\u00f3digos fuente y binarios de las apps que vamos a instalar. </li> </ul> <pre><code>mkdir myApps\ncd myApps\nAPPS_DIR=$(pwd)\nmkdir sources      # source files\nmkdir apps         # binary files\n</code></pre> <ul> <li>Entraremos al directorio <code>sources/</code> y descargaremos el c\u00f3digo fuente del paquete desde su sitio web.</li> </ul> <pre><code>cd $APPS_DIR/sources\nwget  https://www.zlib.net/zlib-1.2.12.tar.xz\n</code></pre> <ul> <li>Descomprimimos el archivo descargado.</li> </ul> <pre><code>tar -xvf zlib-1.2.12.tar.xz\n</code></pre> <ul> <li>Entramos al nuevo directorio con los contenidos del paquete que acabamos de descomprimir.</li> </ul> <pre><code>cd zlib-1.2.12/\n</code></pre> <ul> <li>Cargamos el m\u00f3dulo del compilador para poder crear los binarios a partir del c\u00f3digo fuente. En este caso cargaremos GCC 7.5.0, sin embargo es recomendable seguir los requisitos de cada software. </li> </ul> <pre><code>module load gcc/7.5.0\n</code></pre> <ul> <li>Por lo general, muchos c\u00f3digo fuentes se compilan usando simplemente <code>make</code> y <code>make install</code>. Sin embargo, nosotros debemos configurar previamente el lugar donde se guardaran los binarios, ya que si no hacemos esto, se guardaran en los directorios <code>/usr/lib</code> a los cuales no tenemos acceso. Por lo general, bastar\u00e1 con configurar el argumento <code>--prefix</code>.</li> </ul> <pre><code>./configure --prefix=$APPS_DIR/apps/zlib\n</code></pre> <p>Para mayor informaci\u00f3n de como configurar el path de instalaci\u00f3n, es recomendable seguir la documentaci\u00f3n del software a instalar.</p> <ul> <li>Compilamos el c\u00f3digo fuente.</li> </ul> <pre><code>make \n</code></pre> <ul> <li>Instalamos el software.</li> </ul> <pre><code>make install    # copia los binarios a --prefix\n</code></pre> <ul> <li>Si nos movemos al directorio donde se encuentra la instalaci\u00f3n, encontraremos por lo general una lista de directorios como la siguiente.</li> </ul> <pre><code>cd $APPS_DIR/apps/zlib\nls\n</code></pre> <pre><code># salida del comando anterior\ninclude  lib  share\n</code></pre> <ul> <li>En esos directorios se encuentran los binarios con los cuales podremos hacer uso del software.</li> </ul>"}, {"location": "guia-de-usuario/software/lista/", "title": "Lista de software", "text": ""}, {"location": "guia-de-usuario/software/lista/#modulos-disponibles", "title": "M\u00f3dulos disponibles", "text": "<p>A continuaci\u00f3n se comparte la lista de software disponible:</p> <pre><code>------------------- /opt/ohpc/pub/moduledeps/gnu12-openmpi4 -------------------\n   adios/1.13.1            netcdf-fortran/4.6.0 (D)    scalapack/2.2.0\n   boost/1.81.0            netcdf/4.9.0         (D)    scalasca/2.5\n   dimemas/5.4.2           omb/6.1                     scorep/7.1\n   extrae/3.8.3            opencoarrays/2.10.1         sionlib/1.7.7\n   fftw/3.3.10             petsc/3.18.1                slepc/3.18.0\n   hypre/2.18.1            phdf5/1.10.8                superlu_dist/6.4.0\n   imb/2021.3              pnetcdf/1.12.3              tau/2.31.1\n   mfem/4.4                ptscotch/7.0.1              trilinos/13.4.0\n   mumps/5.2.1             py3-mpi4py/3.1.3\n   netcdf-cxx/4.3.1 (D)    py3-scipy/1.5.4\n\n----------------------- /opt/ohpc/pub/moduledeps/gnu12 ------------------------\n   R/4.2.1            mvapich2/2.3.7              pdtoolkit/3.25.1\n   gsl/2.7.1          netcdf-cxx/4.3.1            plasma/21.8.29\n   hdf5/1.10.8        netcdf-fortran/4.6.0        py3-numpy/1.19.5\n   likwid/5.2.2       netcdf/4.9.0                scotch/6.0.6\n   metis/5.1.0        openblas/0.3.21             superlu/5.2.1\n   mpich/3.4.3-ofi    openmpi4/4.1.6       (L)\n\n-------------------------- /opt/ohpc/pub/modulefiles --------------------------\n   EasyBuild/4.9.1          hwloc/2.7.2      (L)    os\n   autotools         (L)    intel/2023.2.1   (D)    papi/6.0.0\n   charliecloud/0.15        intel/2024.2.1          pmix/4.2.9\n   cmake/3.24.2             libfabric/1.19.0 (L)    prun/2.2        (L)\n   cuda/12.6                magpie/3.0              ucx/1.15.0      (L)\n   gnu12/12.3.0      (L)    ohpc             (L)    valgrind/3.19.0\n\n  Where:\n   D:  Default Module\n   L:  Module is loaded\n</code></pre>"}, {"location": "guia-de-usuario/software/uso/", "title": "Uso de software", "text": ""}, {"location": "guia-de-usuario/software/uso/#modulos", "title": "M\u00f3dulos", "text": "<p>Usted puede listar los m\u00f3dulos que se encuentran disponibles con el siguiente comando.</p> <pre><code>ml av \n# O tambi\u00e9n\nmodule avail\n</code></pre>"}, {"location": "guia-de-usuario/software/uso/#buscar-modulos", "title": "Buscar m\u00f3dulos", "text": "<p>Usted tambi\u00e9n puede buscar m\u00f3dulos mediante el comando <code>avail</code>. Por ejemplo, para listar todas las versiones de MPICH 3, ejecutaremos:</p> <pre><code>module avail mpich/3\n</code></pre> <p>Y obtendremos una salida similar a:</p> <pre><code>--------------------------------------- /opt/apps/modulefiles ----------------------------------------\nmpich/1.5   mpich/3.1.4 mpich/3.2.1 mpich/3.3.2 mpich/3.4.0 mpich/4.0\n</code></pre>"}, {"location": "guia-de-usuario/software/uso/#cargar-modulos", "title": "Cargar m\u00f3dulos", "text": "<p>Usted puede cargar un modulo a su ambiente de trabajo a traves del comando <code>module load</code>. Al cargar un modulo, usted carga todas las variables de ambiente necesarias para poder utilizar dicho paquete de software. </p> <p>Es importante tomar en cuenta que:</p> <ul> <li>El comando es case-sensitive a los nombres de los m\u00f3dulos</li> <li>Cuando usted usa <code>module load</code> se cargan tambi\u00e9n las dependencias del modulo. No es necesario cargarlas de manera separada.</li> <li>Cuando usted envi\u00e1 sus jobs que requieren de un m\u00f3dulo, no olvide a\u00f1adirlo con <code>module load</code> a su bash script.</li> </ul> <p>Por ejemplo, si desea cargar gcc versi\u00f3n 7.5.0, deber\u00e1 ejecutar:</p> <pre><code>module load gcc/7.5.0\n</code></pre> <p>Tambi\u00e9n puede cargar varios m\u00f3dulos al mismo tiempo:</p> <pre><code>module load gcc/7.5.0 mpich/3.3.2\n</code></pre>"}, {"location": "guia-de-usuario/software/uso/#descargar-modulos", "title": "Descargar m\u00f3dulos", "text": "<p>Una vez terminado de usar el software, es recomendable hacer <code>module unload &lt;modulename&gt;</code>. Este proceso tambi\u00e9n se debe realizar e los scripts de los jobs.</p> <pre><code>module unload gcc/7.5.0\n</code></pre> <p>Tambi\u00e9n puede descargar todos los m\u00f3dulos a la vez con:</p> <pre><code>module purge\n</code></pre>"}, {"location": "guia-de-usuario/software/uso/#coleccion-de-modulos", "title": "Colecci\u00f3n de m\u00f3dulos", "text": "<p>En casos cuando se trabaja con gran cantidad de m\u00f3dulos, puede ser molestoso estar cargando cada uno de ellos. Ante esto existe la opci\u00f3n de a\u00f1adir dicho m\u00f3dulos a una colecci\u00f3n y de este modo solo cargar la colecci\u00f3n en lugar que todos los m\u00f3dulos de manera individual. </p> <p>Guardar colecciones</p> <p>Para ello, usted deber\u00e1 cargar previamente los m\u00f3dulos que desea a\u00f1adir a la colecci\u00f3n y despues ejecutar. </p> <p><pre><code>module save &lt;collection-name&gt;\n</code></pre> Cargar colecciones</p> <p>Usted podr\u00e1 cargar la colecci\u00f3n creada con:</p> <p><pre><code>module restore &lt;collection-name&gt;\n</code></pre> Listar colecciones</p> <p>Para listar las colecciones creadas:</p> <pre><code>module savelist\n</code></pre>"}, {"location": "guia-de-usuario/software/uso/#obtener-informacion-y-ayuda-de-los-modulos", "title": "Obtener informaci\u00f3n y ayuda de los m\u00f3dulos", "text": "<p>Si desea mostrar la informaci\u00f3n de configuraci\u00f3n de un modulo en especifico:</p> <pre><code>module show &lt;modulename&gt; #or\nmodule display &lt;modulename&gt;\n</code></pre> <p>Usted puede obtener una breve descripci\u00f3n sobre un m\u00f3dulo ejecutando:</p> <pre><code>module help &lt;modulename&gt;/&lt;version&gt;\n</code></pre> <p>Si usted no encuentra un paquete y considera que su instalaci\u00f3n como modulo podr\u00eda ser beneficiosa para otros usuarios m\u00e1s, puede escribirnos a khipu@utec.edu.pe para solicitar su instalaci\u00f3n.</p>"}, {"location": "info/", "title": "Sobre Khipu", "text": "<p>Khipu es un cluster de Computaci\u00f3n de Alto Desempe\u00f1o (HPC en ingl\u00e9s) que forma parte del Centro de Investigaci\u00f3n para la Computaci\u00f3n Sostenible (COMPSUST) de la Universidad de Ingenier\u00eda y Tecnolog\u00eda (UTEC). En \u00e9l es posible realizar ejecuciones que requieran gran poder de c\u00f3mputo ya sea en CPU o GPU. </p>"}, {"location": "info/#cuanto-cuesta-acceder-a-khipu", "title": "\u00bfCuanto cuesta acceder a Khipu?", "text": "<p>Khipu es gratuito para todos los miembros de la comunidad de UTEC y sus proyectos asociados que requieran de recursos computacionales para sus labores de investigaci\u00f3n. Cualquier miembro de UTEC puede solicitar su acceso a Khipu a travez del formulario de registro que se encuentra en el portal web. Una vez su solicitud haya sido revisada, le ser\u00e1n enviadas sus credenciales de acceso al correo registrado en el formulario. </p> <p>Info</p> <p>Por el momento no se dispone de acceso para personas sin afiliaci\u00f3n a UTEC.</p>"}, {"location": "info/#agradecimiento-citacion", "title": "Agradecimiento / citaci\u00f3n", "text": "<p>Alentamos a todos a los usuarios cuyo proyecto culmine en una publicaci\u00f3n a a\u00f1adir al cluster Khipu dentro de los agradecimientos. Puede a\u00f1adir un mensaje de agradecimiento como el siguiente:</p> <p>\u201cEl trabajo computacional del presente proyecto fue apoyado por los recursos del cluster HPC Khipu (https://web.khipu.utec.edu.pe/) de la Universidad de Ingenier\u00eda y Tecnolog\u00eda (UTEC)\"</p>"}, {"location": "info/#soporte", "title": "Soporte", "text": "<p>Si en caso necesita ayuda o requiere mayor informaci\u00f3n sobre Khipu, por favor escribir al correo  khipu@utec.edu.pe. Si ya posee sus credenciales, por favor genere un ticket a trav\u00e9s del portal de  mesa de ayuda. </p>"}, {"location": "info/infraestructura/", "title": "Infraestructura", "text": ""}, {"location": "info/infraestructura/#nodo-de-acceso", "title": "Nodo de acceso", "text": "<p>Es el nodo mediante el cual se accede al cluster. Es usado principalmente para compilar, enviar y monitorear los jobs.</p> Especificaciones Nombre khipu Procesador Intel(R) Xeon(R) Gold 6230 CPU @ 2.10 GHz 20 cores por socket, 40 por nodo.  Memoria DRAM DDR4-1333 MHz, 128 GB por nodo  Almacenamiento 1TB SSD, 40 TB HDD  Red Infiniband FDR MT4119"}, {"location": "info/infraestructura/#nodos-cpu", "title": "Nodos CPU", "text": "<p>Usados para procesamiento de jobs que requieren de CPU y RAM. Es gerenciado autom\u00e1ticamente por Slurm.</p>"}, {"location": "info/infraestructura/#n003", "title": "n003", "text": "Especificaciones Nombre n003 Procesador Intel(R) Xeon(R) Gold 6130 CPU @2.10 GHz 16 cores por socket, 32 por nodo. Memoria 157 GB DRAM DDR4-1333 MHz  Red Infiniband FDR MT4119"}, {"location": "info/infraestructura/#n004", "title": "n004", "text": "Especificaciones Nombre n004 Procesador Intel(R) Xeon(R) Gold 6130 CPU @2.10 GHz 16 cores por socket, 32 por nodo. Memoria 126 GB DRAM DDR4-1333 MHz  Red Infiniband FDR MT4119"}, {"location": "info/infraestructura/#n005", "title": "n005", "text": "Especificaciones Nombre n003 Procesador Intel(R) Xeon(R) Gold 6130 CPU @2.10 GHz 16 cores por socket, 32 por nodo. Memoria 94 GB DRAM DDR4-1333 MHz  Red Infiniband FDR MT4119"}, {"location": "info/infraestructura/#n006", "title": "n006", "text": "Especificaciones Nombre n006 Procesador Intel(R) Xeon(R) Gold 5418Y 2.0 GHz 24 cores por socket, 48 por nodo.  Memoria  1TB DRAM DDR5 5600MHz Red Infiniband Mellanox MT28908"}, {"location": "info/infraestructura/#nodos-gpu", "title": "Nodos GPU", "text": "<p>Usados para procesamiento de jobs que requieren de CPU, RAM y/o GPU. Es gerenciado autom\u00e1ticamente por Slurm.</p>"}, {"location": "info/infraestructura/#g001", "title": "g001", "text": "Especificaciones Nombre g001 Procesador Intel(R) Xeon(R) Gold 6230 CPU @2.10 GHz 16 cores por socket, 32 por nodo.  Gr\u00e1ficos NVIDIA Tesla T4 16 GB GDDR6 Memoria  157 GB DRAM DDR4-1333 MHz Red Infiniband FDR MT4119"}, {"location": "info/infraestructura/#g002", "title": "g002", "text": "Especificaciones Nombre g002 Procesador Intel(R) Xeon(R) Gold 5418Y 2.0 GHz 24 cores por socket, 48 por nodo.  Gr\u00e1ficos NVIDIA RTX A6000 48 GB GDDR6 Memoria  1TB DRAM DDR5 5600MHz Red Infiniband Mellanox MT28908"}, {"location": "info/infraestructura/#ag001", "title": "ag001", "text": "Especificaciones Nombre ag001 Procesador AMD EPYC 7742 64-Core Processor 64 cores por socket, 128 por nodo.  Gr\u00e1ficos x2 NVIDIA A100 40 GB GDDR6 Memoria  1TB DRAM DDR4 Red Infiniband Mellanox MT28908"}, {"location": "info/infraestructura/#nodos-ciencia-de-datos", "title": "Nodos Ciencia de Datos", "text": ""}, {"location": "info/infraestructura/#ds001", "title": "ds001", "text": "Especificaciones Nombre ds001 Procesador Intel(R) Xeon(R) Gold 5418Y 2.0 GHz 24 cores por socket, 48 por nodo.  Gr\u00e1ficos NVIDIA RTX A6000 48 GB GDDR6 Memoria  1TB DRAM DDR5 5600MHz Red Infiniband Mellanox MT28908"}, {"location": "info/infraestructura/#software-del-sistema", "title": "Software del sistema", "text": "<ul> <li>Sistema Operativo: Rocky Linux 8.10 (Green Obsidian)</li> <li>Message Passing Library: MPICH</li> <li>Compiladores: Intel, GCC</li> <li>Job Scheduler: SLURM </li> <li>Manejo de software: M\u00f3dulos de ambiente</li> </ul>"}, {"location": "info/politicas-de-uso/", "title": "Pol\u00edticas de uso", "text": "<p>El uso del cluster HPC Khipu est\u00e1 sujeto al cumplimiento de sus pol\u00edticas de uso. Los usuario se comprometen a cumplir con cada una de ellas una vez que reciben sus credenciales de acceso.</p>"}, {"location": "info/politicas-de-uso/#sobre-las-cuentas", "title": "Sobre las cuentas", "text": "<ul> <li>Solo los usuarios registrados pueden acceder a Khipu. Asimismo, los usuarios se hacen responsables de tomar las precauciones necesarias para proteger sus credenciales de acceso y as\u00ed impedir accesos no autorizados. </li> <li>Los usuarios se encuentran prohibidos de compartir sus credenciales con otras personas, as\u00ed sean estos estudiantes o colaboradores. Del mismo modo, los usuarios se encuentran prohibidos de acceder a Khipu con credenciales que no son suyas, con o sin consentimiento del usuario. </li> <li>En caso de existir sospecha que otros han usado su cuenta, notificarlo inmediatamente a khipu@utec.edu.pe</li> <li>Las cuentas ser\u00e1n desactivadas si una de las siguientes condiciones se cumple:</li> <li>La fecha de fin del curso o proyecto ha sido alcanzada.</li> <li>El encargado del curso o proyecto indica que el usuario ya no requiere acceso.</li> <li>El usuario ha recibido alguna sanci\u00f3n disciplinaria de parte de la universidad.</li> <li>Si una cuenta se encuentra desactivada por m\u00e1s de 30 d\u00edas, ser\u00e1 eliminada permanentemente. </li> </ul>"}, {"location": "info/politicas-de-uso/#sobre-el-uso", "title": "Sobre el uso", "text": "<p>El cluster Khipu es un recurso compartido por multiples usuarios, as\u00ed que las acciones que usted realice pueden afectar a otros usuarios si no se realizan de manera adecuada. Es por ello, que se brindan las siguientes recomendaciones a fin de garantizar un uso equitativo y justo de los recursos del cluster.</p> <ul> <li>El uso del cluster se encuentra restringido solo para fines educativos y de investigaci\u00f3n. Su uso no debe estar relacionado a actividades comerciales, de consultor\u00eda o creaci\u00f3n y/o ejecuci\u00f3n de software malicioso.</li> <li>Los usuarios son responsables de usar los recursos del cluster de manera eficiente, efectiva, \u00e9tica y l\u00edcita.</li> <li>El nodo de acceso es usado para acceder al cluster, editar archivos, compilar c\u00f3digo y enviar trabajos. De ninguna manera, se deben ejecutar los trabajos directamente en el nodo de acceso.</li> <li>Toda ejecuci\u00f3n de trabajos debe ser realizada a traves del gestor de colas Slurm. Es as\u00ed como se garantizan un uso eficiente y justo de los recursos.</li> <li>El cluster no debe ser utilizado como almacenamiento personal. Se recomienda copiar sus resultados a su m\u00e1quina personal de manera peri\u00f3dica. Khipu no cuenta con backups de sus discos.</li> <li>Los usuarios no deben intentar acceder a cualquier archivo o programa al cual no poseen autorizaci\u00f3n o un consentimiento expl\u00edcito del due\u00f1o del archivo o programa.</li> <li>Los usuarios pueden hacer uso de las aplicaciones ya instaladas, y tambi\u00e9n compilar nuevas aplicaciones en su espacio personal solamente si fueran necesarios para el desarrollo de su proyecto o trabajo.</li> <li>Los softwares que se instalen deben incluir una licencia v\u00e1lida (si es aplicable). No se puede instalar software de procedencia ilegal y/o con licencia no otorgada por los desarrolladores.</li> <li>La presente pol\u00edtica ser\u00e1 revisada y actualizada de manera peri\u00f3dica. Cualquier cambio ser\u00e1 comunicado al correo electr\u00f3nico registrado.</li> </ul>"}, {"location": "info/politicas-de-uso/#incumplimiento-de-las-reglas-de-uso", "title": "Incumplimiento de las reglas de uso", "text": "<p>El usuario acepta cumplir con la normativa y sanciones impuestas por UTEC en sus atribuciones.    - En caso de no cumplir normas de UTEC y/o atentar contra la ley, el evento ser\u00e1 notificado a las autoridades pertinentes.    - En caso de incumplimiento de los items anteriores, la cuenta ser\u00e1 suspendida. </p>"}, {"location": "info/politicas-de-uso/#agradecimientos-por-el-uso-de-khipu", "title": "Agradecimientos por el uso de Khipu", "text": "<p>Alentamos a todos a los usuarios, cuyo proyecto termina en una publicaci\u00f3n o presentaci\u00f3n, a a\u00f1adir al cluster Khipu dentro de los agradecimientos. Su sola menci\u00f3n contribuye a comunicar el rol de Khipu en el desarrollo de investigaciones dentro de la universidad, a incentivar a m\u00e1s estudiantes y docentes a incorporar a Khipu dentro de sus proyectos o planes de estudio, a mantener el financiamiento y soporte que hace posible que Khipu siga creciendo cada d\u00eda m\u00e1s. </p> <p>Puede a\u00f1adir un mensaje de agradecimiento como el siguiente:</p> <p>\"El trabajo computacional del presente proyecto fue apoyado por los recursos del cluster HPC Khipu de la Universidad de Ingenier\u00eda y Tecnolog\u00eda (UTEC) \"</p>"}, {"location": "info/politicas-de-uso/#comunicacion", "title": "Comunicaci\u00f3n", "text": "<p>El correo electr\u00f3nico ingresado al momento de solicitar acceso a Khipu ser\u00e1 el medio por el cual se enviar\u00e1n anuncios relevantes al funcionamiento del cluster. Si usted presenta preguntas, pedidos o requiere asistencia puede escribir de manera directa a khipu@utec.edu.pe. </p>"}, {"location": "info/tipos-de-cuentas/", "title": "Tipos de cuentas", "text": "<p>Existen diferentes grupos de usuarios que son gerenciados de manera autom\u00e1tica por Slurm. De manera general podemos agruparlos en: educaci\u00f3n e investigaci\u00f3n.</p>"}, {"location": "info/tipos-de-cuentas/#grupo-educacion", "title": "Grupo Educaci\u00f3n", "text": "<p>Permite el uso del cluster por los estudiantes de pregrado o posgrado, a pedido de un instructor(a) registrado(a), en el marco del desarrollo de un curso. De acuerdo al tipo de estudiantes (pregrado o posgrado) se disponen los siguiente l\u00edmites:</p>"}, {"location": "info/tipos-de-cuentas/#pregrado", "title": "Pregrado", "text": "<ul> <li>Particiones disponibles: debug, debug-gpu, standard, gpu</li> <li>Cantidad m\u00e1xima de recursos por usuario: 32 cores, 98GB RAM y 8 shards GPU</li> <li>Tiempo m\u00e1ximo de ejecuci\u00f3n por job (Walltime): 8 horas</li> </ul>"}, {"location": "info/tipos-de-cuentas/#posgrado", "title": "Posgrado", "text": "<ul> <li>Particiones disponibles: debug, debug-gpu, standard, gpu</li> <li>Cantidad m\u00e1xima de recursos por usuario: 32 cores, 98GB RAM y 8 shards GPU</li> <li>Tiempo m\u00e1ximo de ejecuci\u00f3n por job (Walltime): 8 horas</li> </ul>"}, {"location": "info/tipos-de-cuentas/#docencia", "title": "Docencia", "text": "<ul> <li>Particiones disponibles: debug, debug-gpu, standard, gpu</li> <li>Cantidad m\u00e1xima de recursos por usuario: 32 cores, 98GB RAM y 32 shards GPU</li> <li>Tiempo m\u00e1ximo de ejecuci\u00f3n por job (Walltime): 8 horas</li> </ul>"}, {"location": "info/tipos-de-cuentas/#grupo-investigacion", "title": "Grupo Investigaci\u00f3n", "text": "<p>Permite el uso del cluster para todos aquellos miembros de UTEC y asociados que requieran de recursos computacionales para el desarrollo de un proyecto de investigaci\u00f3n. La solicitud de acceso es registrada por el investigador principal (PI). De acuerdo al proyecto se disponen los siguiente niveles y l\u00edmites por nivel:</p>"}, {"location": "info/tipos-de-cuentas/#tesis", "title": "Tesis", "text": "<ul> <li>Particiones disponibles: debug, debug-gpu, standard, gpu, big-mem</li> <li>Cantidad m\u00e1xima de recursos por usuario: 32 cores, 96GB RAM y 40 shards GPU</li> <li>Tiempo m\u00e1ximo de ejecuci\u00f3n por job (Walltime): 24 horas</li> </ul>"}, {"location": "info/tipos-de-cuentas/#investigacion-nivel-i", "title": "Investigaci\u00f3n Nivel I", "text": "<ul> <li>Particiones disponibles: debug, debug-gpu, standard, gpu, big-mem</li> <li>Cantidad m\u00e1xima de recursos por usuario: 48 cores, 120GB RAM y 40 shards GPU</li> <li>Tiempo m\u00e1ximo de ejecuci\u00f3n por job (Walltime): 48 horas</li> </ul>"}, {"location": "info/tipos-de-cuentas/#investigacion-nivel-ii", "title": "Investigaci\u00f3n Nivel II", "text": "<ul> <li>Particiones disponibles: debug, debug-gpu, standard, gpu, big-mem</li> <li>Cantidad m\u00e1xima de recursos por usuario: 96 cores, 162GB RAM y 80 shards GPU</li> <li>Tiempo m\u00e1ximo de ejecuci\u00f3n por job (Walltime): 96 horas</li> </ul>"}, {"location": "info/tipos-de-cuentas/#como-puedo-saber-mi-tipo-de-cuenta", "title": "\u00bfC\u00f3mo puedo saber mi tipo de cuenta?", "text": "<p>Una vez inicies sesi\u00f3n en Khipu, ejecuta el siguiente comando:</p> <p><pre><code>myaccount\n</code></pre> Y obtendr\u00e1s el nombre de tu cuenta y sus l\u00edmites. La salida en pantalla ser\u00e1 similar a:</p> <pre><code>$ myaccount\n---------------------------------------------------------\nKhipu account                                            \n---------------------------------------------------------\nUser                 Account            Default          \n-------------------- ------------------ -----------------\naturin               docencia           docencia           \n\n--------------------------------------------------------------\nAccount Limits                                                \n--------------------------------------------------------------\nAccount           Resources                       TimeLimit   \n----------------- ------------------------------- ------------\na-docencia        cpu=32,gres/shard=32,mem=98G      08:00:00 \n</code></pre>"}, {"location": "primeros-pasos/", "title": "Empezar a usar Khipu", "text": "<p>Para empezar a usar Khipu es necesario seguir los siguientes pasos:</p> <ol> <li> <p>Solicitar una cuenta de usuario y esperar el env\u00edo de sus credenciales.</p> </li> <li> <p>Acceder a Khipu con un cliente SSH y cambiar su contrase\u00f1a (Opcional). </p> </li> <li> <p>Configurar un par de llaves SSH (Opcional si desea acceder sin escribir su contrase\u00f1a).</p> </li> <li> <p>Si fuera necesario, transferir sus archivos a Khipu.</p> </li> <li> <p>Revisar la dem\u00e1s gu\u00edas de uso de Khipu.</p> </li> </ol> <p> \u00bfNecesita ayuda?</p> <p>Si en caso necesita ayuda o requiere mayor informaci\u00f3n para realizar el primer paso, por favor escribir al correo  khipu@utec.edu.pe. Si ya posee sus credenciales y tiene problemas del segundo paso en adelante, por favor genere un ticket a trav\u00e9s del portal de  mesa de ayuda. </p>"}, {"location": "primeros-pasos/acceder-a-khipu/", "title": "Acceder a Khipu", "text": "<p>Nota</p> <p>Para los siguientes comandos necesita tener una cuenta activa en Khipu. </p> <p>El acceso a Khipu se realiza a trav\u00e9s de la  interfaz de comandos o terminal que se encuentra disponible en la mayor\u00eda de sistemas operativos. Para ello se hace uso de un cliente SSH. En  Windows, tenemos clientes como <code>cmd</code>, <code>powershell</code> o Putty. Mientras que en  Linux y  MacOS ya incluyen una terminal que viene por defecto.</p>"}, {"location": "primeros-pasos/acceder-a-khipu/#inicio-de-sesion", "title": "Inicio de sesi\u00f3n", "text": "<ul> <li>Abra una terminal y ejecute el siguiente comando. No olvide reemplazar  por su nombre de usuario.  <pre><code>ssh &lt;username&gt;@khipu.utec.edu.pe\n</code></pre> Host keys <p>Si es la primera vez que accede a Khipu le aparecer\u00e1 un mensaje similar al siguiente:</p> <pre><code>The authenticity of host 'khipu.utec.edu.pe' can't be established.\nED25519 key fingerprint is SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.\nAre you sure you want to continue connecting (yes/no)?\n</code></pre> <p>Ese mensaje de advertencia es normal y aparece la primera vez que su cliente SSH se conecta a un ordenador nuevo.  Escriba <code>yes</code> y presione Enter para que se le solicite su contrase\u00f1a de acceso.</p> <ul> <li>Escriba su contrase\u00f1a y presione Enter . Una vez hecho esto, usted habr\u00e1 iniciado sesi\u00f3n en el cluster y tendr\u00e1 el siguiente mensaje:</li> </ul> <pre><code>Last login: Mon Nov  4 17:30:01 2024 from *.*.*.*\n\n         --*-*- Sustainable Computing Research Center -*-*--\n\n                 _  ___     _             \n                | |/ / |   (_)            \n                | ' /| |__  _ _ __  _   _ \n                |  &lt; | '_ \\| | '_ \\| | | |\n                | . \\| | | | | |_) | |_| |\n                |_|\\_\\_| |_|_| .__/ \\__,_| v3.0\n                             | |          \n                             |_|          \n\n===========================================================================\n  This system is for authorized users only and users must comply with all\n  Khipu computing, network and research policies. All activity may be\n  recorded for security and monitoring purposes. \n===========================================================================\n\n            Docs          https://docs.khipu.utec.edu.pe\n            Support       khipu@utec.edu.pe\n\n ===================[ Maintenance Information ]============================\n\n No maintenance information.\n\n===========================================================================\n Good evening &lt;username&gt;!\n</code></pre> <p>Warning</p> <p>Ingresar su contrase\u00f1a de manera incorrecta en un periodo corto de tiempo provocar\u00e1 que el acceso a Khipu desde su IP p\u00fablica sea bloqueado.</p> <ul> <li> <p>\u00a1Felicidades , ya se encuentra dentro de Khipu! </p> </li> <li> <p>\u00a1Opcional! Revise la siguiente gu\u00eda si desea acceder a Khipu usando llaves SSH.</p> </li> </ul>"}, {"location": "primeros-pasos/acceder-a-khipu/#problemas-frequentes", "title": "Problemas frequentes", "text": ""}, {"location": "primeros-pasos/acceder-a-khipu/#1-timeouts", "title": "1. Timeouts", "text": "<p>Si usted obtiene un mensaje de error parecido al siguiente:</p> <p><pre><code>ssh: connect to host khipu.utec.edu.pe port 22: Operation timed out\n</code></pre> Pruebe connectarse a una conecci\u00f3n de internet m\u00e1s estable como una red cableada o cambie de red WiFi. Si el error ocurre dentro del campus o se encuentra fuera de Per\u00fa, por favor genere un ticket en  mesa de ayuda.</p>"}, {"location": "primeros-pasos/acceder-a-khipu/#2-fallas-de-autenticacion", "title": "2. Fallas de autenticaci\u00f3n", "text": "<pre><code>ssh: connect to host khipu.utec.edu.pe port 22: Connection refused\n</code></pre> <p>Como medida para prevenir ataque de fuerza bruta, Khipu cuenta con un bloqueo automatizado de las IPs desde las cuales se realizan inicios fallidos de sesi\u00f3n en  un periodo corto de tiempo.  Si usted ingresa su contrase\u00f1a de manera incorrecta m\u00e1s de tres veces seguidas, provocar\u00e1 que el acceso a Khipu desde su IP p\u00fablica sea bloqueado y le aparecer\u00e1 un mensaje como el de arriba. Para restablecer su contrase\u00f1a o desbloquear el acceso desde su IP p\u00fablica, debe generar un ticket en  mesa de ayuda. </p>"}, {"location": "primeros-pasos/cambiar-contrasena/", "title": "Cambio de contrase\u00f1a", "text": "<p>Olvido de contrase\u00f1a</p> <p>Si usted olvid\u00f3 su contrase\u00f1a, genere un ticket en  mesa de ayuda para que se le genere una nueva contrase\u00f1a. Esta gu\u00eda es para cambiar su contrase\u00f1a si conoce la anterior.</p> <p>Usted puede cambiar la contrase\u00f1a que recibi\u00f3 en el correo de bienvenida a Khipu.  A continuaci\u00f3n le mostraremos como hacerlo. </p> <ol> <li>Inicie sesi\u00f3n en Khipu. Si no sabe como hacerlo, revise el siguiente enlace.</li> <li> <p>Luego ejecute el comando <code>passwd</code> y siga lo que se le indica en pantalla.</p> <ul> <li>Se le pedir\u00e1 que escriba su contrase\u00f1a actual.</li> <li>Se le pedir\u00e1 que escriba la nueva contrase\u00f1a</li> <li>Se le pedir\u00e1 que repita la nueva contrase\u00f1a</li> </ul> </li> <li> <p>Listo, ya cambi\u00f3 su contrase\u00f1a en Khipu.</p> </li> </ol>"}, {"location": "primeros-pasos/cambiar-contrasena/#recomendaciones-de-seguridad", "title": "Recomendaciones de seguridad", "text": "<p>Warning</p> <p>Recuerde proteger sus credenciales de acceso y no compartirlas con ning\u00fan otra persona. El uso inadecuado de los servicios del cluster es resposabilidad del titular de la cuenta. </p> <p>Generar contrase\u00f1as fuertes y seguras es fundamental para garantizar su seguridad y la del cluster. Para ello le compartimos las siguientes recomendaciones.</p> <ul> <li>Utilice un m\u00ednimo de 12 caracteres</li> <li>Combine diferentes tipos de caracteres como n\u00fameros, letras o caracteres especiales. </li> <li>No use palabras comunes o f\u00e1ciles de adivinar.</li> <li>No use informaci\u00f3n personal predecible.</li> </ul>"}, {"location": "primeros-pasos/configurar-llaves-ssh/", "title": "Configurar llaves SSH", "text": "<p>Es posible acceder a Khipu usando un par de llaves SSH. La llave p\u00fablica deber\u00e1 copiarla a Khipu, mientras que la privada debe permanecer en su ordenador. </p>"}, {"location": "primeros-pasos/configurar-llaves-ssh/#generacion-de-llaves-ssh", "title": "Generaci\u00f3n de llaves SSH", "text": "Desde una terminal ( Linux,   MacOS o  Windows) <p>El par de llaves SSH puede ser generado usando  Linux,   MacOS o  Windows. Para ello abra una terminal en su computadora local y ejecute el siguiente comando:</p> <pre><code>ssh-keygen -t ed25519\n</code></pre> <p>Su terminal responder\u00e1 preguntando por un nombre y lugar donde guardar el par de llaves. Si desea optar por la opci\u00f3n por defecto, presione Enter. Si desea un nombre y lugar distino escr\u00edbalo en pantalla. Tambien puede especificar el lugar y nombre de manera directa a\u00f1adiendo el flag <code>-f &lt;filename&gt;</code> al comando  anterior. A continuaci\u00f3n se muestra un ejemplo del comando completo:</p> <pre><code>ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519\n</code></pre> <p>Luego se le pedir\u00e1 que ingrese un passphrase (1). Este debe tener una longitud de por lo menos 8 caracteres (preferiblemente 12). El passphrase debe ser preferiblemente una combinaci\u00f3n de n\u00fameros, letras y caracteres especiales para tener mayor seguridad. Una vez escrito, presione Enter para continuar.</p> <ol> <li> Un passphrase es una secuencia de palabras o una frase completa que se utiliza como contrase\u00f1a.</li> </ol> <p>Olvido de passphrase</p> <p> Si usted olvida su passphrase, no podr\u00e1 recuperarlo. En cambio, usted deber\u00e1 eliminar el par de llaves anterior y generar una nuevas.</p> <p>Finalmente se generar\u00e1n un par de llaves SSH en la locaci\u00f3n que especific\u00f3 (<code>~/.ssh/</code> en el ejemplo anterior). El par de llaves incluye una llave privada <code>id_ed25519</code> y una p\u00fablica <code>id_ed25519.pub</code>. </p> <p>Advertencia</p> <p>La llave privada no debe ser compartida con nadie, incluyendo Khipu. Esta llave debe permanecer almacenada en el ordenador donde fue generada. La llave p\u00fablica es la \u00fanica que ser\u00e1 compartida y almacenada en el cluster. Utilice un passphare robusto para proteger sus llaves en caso de robo y prevenir un uso no autorizado de las mismas.</p>"}, {"location": "primeros-pasos/configurar-llaves-ssh/#copiar-su-llave-publica-a-khipu", "title": "Copiar su llave p\u00fablica a Khipu", "text": "<p>A continuaci\u00f3n se muestra como copiar su clave p\u00fablica a Khipu desde diferentes sistemas operativos:</p> Desde una terminal ( Linux y    MacOS) Windows <p>Ejecute desde su terminal <code>ssh-copy-id -i &lt;ubicaci\u00f3n-de-la-llave-p\u00fablica&gt; &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe</code>. Por ejemplo, para las llaves generadas en los pasos anteriores el comando a ejecutar ser\u00e1:</p> <pre><code>ssh-copy-id -i ~/.ssh/id_ed25519.pub &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe\n</code></pre> <p>Si el par de llaves del ejemplo anterior hubieran sido generadas en  Windows,  el comando a usar ser\u00e1:  <pre><code>type ~/.ssh/id_ed25519.pub | ssh &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe \"mkdir -p .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys\"\n</code></pre></p> <p>Tambi\u00e9n, puede optar por copiar el contenido de la llave p\u00fablica <code>id_ed25519.pub</code> y escribirlo en Khipu en <code>.ssh/authorized_keys</code> usando un editor de texto como <code>vim</code> o <code>nano</code>.</p> <p>Info</p> <p>Una vez que su llave p\u00fablica fue copiada en Khipu correctamente, usted podr\u00e1 acceder a Khipu usando sus llaves SSH. A diferencia del inicio de sesi\u00f3n con contrase\u00f1a, el passphrase le ser\u00e1 solicitado una sola vez por inicio de sesi\u00f3n de su ordenador local. </p>"}, {"location": "primeros-pasos/siguientes-pasos/", "title": "Siguientes pasos", "text": "<p>Por favor revise los siguientes enlaces:</p> <ul> <li>Informaci\u00f3n sobre la infraestructura disponible. </li> <li>Pol\u00edticas de uso</li> <li>\u00bfComo enviar jobs?</li> <li>Software disponible</li> <li>Anuncios</li> <li>\u00bfC\u00f3mo solicitar ayuda?</li> </ul>"}, {"location": "primeros-pasos/solicitar-acceso/", "title": "Solicitar acceso a Khipu", "text": "<p>Para poder acceder a Khipu, es necesario formar parte de UTEC o de un proyecto en conjunto con UTEC. </p> <p>El acceso puede darse a trav\u00e9s de proyectos (para su uso en investigaci\u00f3n) o cursos (para su uso acad\u00e9mico). </p> <ul> <li>Si desea solicitar acceso para su  proyecto, el investigador principal (PI) debe completar el siguiente formulario.     </li> <li>Si el proyecto es una  tesis de pregrado o posgrado, el alumno responsable de la tesis en conjunto con su asesor deber\u00e1 completar el siguiente formulario.</li> <li>Si desea solicitar acceso a Khipu para su  curso, el profesor responsable (PR) del dictado del curso debe completar el siguiente formulario. </li> </ul> <p>Una vez completado el formulario respectivo, la solicitud de acceso ser\u00e1 revisada y la respuesta comunicada al correo electr\u00f3nico registrado. </p> <ul> <li> <p>Si la solicitud es favorable, se comunicar\u00e1 la respuesta y se realizar\u00e1 el env\u00edo de credenciales de acceso a los correos electr\u00f3nicos de cada miembro registrado. Una vez que un usuario recibe sus credenciales, se compromete a cumplir con las pol\u00edticas de uso. </p> </li> <li> <p>Si la solicitud no es favorable o se requiere mayor informaci\u00f3n, la comunicaci\u00f3n se realizar\u00e1 por correo electr\u00f3nico.</p> </li> </ul>"}, {"location": "primeros-pasos/transferir-archivos/", "title": "Transferir archivos hacia/desde Khipu", "text": "<p>Info</p> <p>Se recomienda realizar regularmente copias de sus archivos en Khipu a sus ordenadores locales. Es importante recordar que Khipu no es un  almacenamiento personal en la nube y que la informaci\u00f3n almacenada no posee respaldo. </p> <p>La transferencia de archivos hacia/desde Khipu puede ser realizada usando <code>scp</code> o <code>rsync</code>.</p>"}, {"location": "primeros-pasos/transferir-archivos/#copiando-archivos-usando-scp", "title": "Copiando archivos usando <code>scp</code>", "text": "Secure Copy Protocol <code>scp</code> <p><code>scp</code> es un comando que permite copiar de manera secura archivos y directorios desde dos ubicaciones remotas. Con este comando podremos copiar archivos o directorios desde nuestro ordenador local a uno remoto y viceversa. Cuando se transfiere datos mediante <code>scp</code> los archivos y contrase\u00f1as son encriptados para evitar que alguien tenga acceso no autorizado mientras se realiza el proceso de copia. </p> <p>La sintaxis b\u00e1sica del comando <code>scp</code> es la siguiente:</p> <p><pre><code>scp &lt;path-origen&gt; &lt;path-destino&gt;\n</code></pre> A continuaci\u00f3n se muestran algunos ejemplos:</p> <ul> <li> <p>Copiar desde mi ordenador local a Khipu</p> <pre><code># Copiar `mi-archivo.txt` al directorio `/home/&lt;usuario-en-khipu&gt;` (`~`) en Khipu\nscp mi-archivo.txt &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe:~\n\n# Copiar `mi-folder/` al directorio `/home/&lt;usuario-en-khipu&gt;` (`~`) en Khipu\n# El flag -r indica que se esta ejecutando el comando de manera recursiva.\nscp -r mi-folder/ &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe:~\n</code></pre> </li> <li> <p>Copiar de Khipu a mi ordenador local</p> <pre><code># Copiar `mi-archivo-en-khipu.txt` al directorio actual de mi ordenador\nscp mi-usuario@khipu.utec.edu.pe:~/path/a/mi-archivo-en-khipu.txt .\n\n# Copiar `mi-folder-en-khipu/` al directorio actual de mi ordenador\nscp -r mi-usuario@khipu.utec.edu.pe:~/path/a/mi-folder-en-khipu/ .\n</code></pre> </li> </ul>"}, {"location": "primeros-pasos/transferir-archivos/#copiando-archivos-usando-rsync", "title": "Copiando archivos usando <code>rsync</code>", "text": "Remote Synchronization <code>rsync</code> <p><code>rsync</code> es una herramienta de sincronizaci\u00f3n entre archivos remotos y locales. Este comando minimiza la cantidad de datos copiados, ya que solo copia aquellas partes que cambiaron entre ambos directorios. Este comando es recomendado para la transferencia de archivos de gran tama\u00f1o ya que mantiene un registro del progreso. De esta manera, si la transmisi\u00f3n es interrumpida, <code>rsync</code> continuar\u00e1 desde donde se qued\u00f3, sin necesidad de iniciar desde cero.</p> <p>La sintaxis b\u00e1sica para el uso de <code>rsync</code> es la siguiente:</p> <pre><code>rsync &lt;opciones&gt; &lt;path-origen&gt; &lt;path-destino&gt;\nrsync &lt;opciones&gt; &lt;path-origen-local&gt; &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe:&lt;path-destino-en-Khipu&gt;\nrsync &lt;opciones&gt; &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe:&lt;path-origen-en-Khipu&gt; &lt;path-destino-local&gt;\n</code></pre> <p>A continuaci\u00f3n se muestran algunos ejemplos del uso de <code>rsync</code>.</p> <ul> <li> <p>Sincronizar desde mi ordenador local a Khipu</p> <pre><code># El flag -a indica que se trata de archivos\nrsync -a ~/path/en/mi-folder &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe:~/path/en/khipu\n\n# El flag -az indica que se trata de archivos que se van a comprimir\nrsync -az ~/path/en/mi-folder &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe:~/path/en/khipu\n</code></pre> </li> <li> <p>Sincronizar un directorio remoto a uno local</p> <pre><code># El flag -a indica que se trata de archivos\nrsync -a &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe:~/path/en/khipu ~/path/en/mi-folder-local\n\n# El flag -azP indica que se trata de archivos que se van a comprimir y se muestra el progreso\nrsync -azP &lt;usuario-en-khipu&gt;@khipu.utec.edu.pe:~/path/en/khipu ~/path/en/mi-folder-local\n</code></pre> </li> </ul>"}, {"location": "software/_index/", "title": "Software", "text": ""}, {"location": "software/_index/#modulos", "title": "M\u00f3dulos", "text": "<p>Los sofwares disponibles se realizan a traves de sotfware modules. Esto nos permite contar con diferentes versiones del mismo software sin mayores conflictos.  Los m\u00f3dulos ayudan a cambiar entre diferentes aplicaciones y sus versiones con relativa facilidad, especialmente en ambientes compartidos. Puede encontrar la lista de software disponible aqu\u00ed.</p>"}, {"location": "software/_index/#pedidos-de-instalacion", "title": "Pedidos de instalaci\u00f3n", "text": "<p>Si el software que necesita no se encuentra en la lista de software disponible, y usted tiene problemas para instalarlo de manera local, por favor escriba a khipu@utec.edu.pe brindando la mayor cantidad de detalles posibles sobre el software que necesita. Si el software es licenciado, incluya en enlace a la web del proveedor y su respectiva licencia. </p>"}, {"location": "software/instalacion/", "title": "Instalaci\u00f3n de software", "text": "<p>El siguiente documento describe como instalar software en Khipu para un proyecto o curso. Antes de realizar una instalaci\u00f3n, por favor revise si el software ya se encuentra disponible como m\u00f3dulo con el comando <code>module avail</code> o <code>ml av</code>.</p>"}, {"location": "software/instalacion/#requisitos-para-instalar-software", "title": "Requisitos para instalar software", "text": "<ul> <li>En caso de software licenciado, el usuario debe proveer la licencia y/o instalador del software al administrador para ser instalado. </li> <li>El usuario puede instalar el software y libraries necesarios en su <code>/home/&lt;username&gt;/</code>, en caso de no requerir licencia o ser de c\u00f3digo abierto. </li> <li>El usuario puede compilar en el nodo l\u00edder antes de enviar un job a ejecutar. No enviar jobs de compilaci\u00f3n a la fila del cluster. </li> <li>Siendo Khipu un cluster enfocado al procesamiento y HPC; no se instalar\u00e1n bases de datos, containers o m\u00e1quinas virtuales. </li> <li>Si el software o library requiere permisos especiales para instalaci\u00f3n, solamente el profesor encargado del curso o un investigador de proyecto pueden solicitar la instalaci\u00f3n bajo coordinaci\u00f3n con el administrador. </li> </ul> <ul> <li>Si el software que planea instalar posee dependencias como librer\u00edas, interfaces o m\u00f3dulos; revise primero si ya se encuentran disponibles en el cluster antes de instalarlas por su cuenta. </li> </ul> <p>Para entrar en contacto con el administrador del cluster, por favor enviar un mensaje a khipu@utec.edu.pe.</p>"}, {"location": "software/instalacion/#proceso-de-instalacion", "title": "Proceso de instalaci\u00f3n", "text": "<p>Tal como se mencion\u00f3 anteriormente, usted puede instalar software libre o que no requiere licencia en su espacio personal de trabajo. Sin embargo, antes de proceder con la instalaci\u00f3n aseg\u00farese que dicho software no requiere permisos root para ser instalado. Una vez echo esto, usted deber\u00e1 moverse al directorio en el cual planea realizar la instalaci\u00f3n y seguir las instrucciones del proveedor del software que planea instalar. </p> <p>Por lo general, los pasos son similares, es por ello que a continuaci\u00f3n se muestra un ejemplo realizando la instalaci\u00f3n de la librer\u00eda Zlib, un software usado para comprimir y descomprimir data.</p> <ul> <li>Creamos un directorio en el cual almacenaremos los c\u00f3digos fuente y binarios de las apps que vamos a instalar. </li> </ul> <pre><code>mkdir myApps\ncd myApps\nAPPS_DIR=$(pwd)\nmkdir sources      # source files\nmkdir apps         # binary files\n</code></pre> <ul> <li>Entraremos al directorio <code>sources/</code> y descargaremos el c\u00f3digo fuente del paquete desde su sitio web.</li> </ul> <pre><code>cd $APPS_DIR/sources\nwget  https://www.zlib.net/zlib-1.2.12.tar.xz\n</code></pre> <ul> <li>Descomprimimos el archivo descargado.</li> </ul> <pre><code>tar -xvf zlib-1.2.12.tar.xz\n</code></pre> <ul> <li>Entramos al nuevo directorio con los contenidos del paquete que acabamos de descomprimir.</li> </ul> <pre><code>cd zlib-1.2.12/\n</code></pre> <ul> <li>Cargamos el m\u00f3dulo del compilador para poder crear los binarios a partir del c\u00f3digo fuente. En este caso cargaremos GCC 7.5.0, sin embargo es recomendable seguir los requisitos de cada software. </li> </ul> <pre><code>module load gcc/7.5.0\n</code></pre> <ul> <li>Por lo general, muchos c\u00f3digo fuentes se compilan usando simplemente <code>make</code> y <code>make install</code>. Sin embargo, nosotros debemos configurar previamente el lugar donde se guardaran los binarios, ya que si no hacemos esto, se guardaran en los directorios <code>/usr/lib</code> a los cuales no tenemos acceso. Por lo general, bastar\u00e1 con configurar el argumento <code>--prefix</code>.</li> </ul> <pre><code>./configure --prefix=$APPS_DIR/apps/zlib\n</code></pre> <p>Para mayor informaci\u00f3n de como configurar el path de instalaci\u00f3n, es recomendable seguir la documentaci\u00f3n del software a instalar.</p> <ul> <li>Compilamos el c\u00f3digo fuente.</li> </ul> <pre><code>make \n</code></pre> <ul> <li>Instalamos el software.</li> </ul> <pre><code>make install    # copia los binarios a --prefix\n</code></pre> <ul> <li>Si nos movemos al directorio donde se encuentra la instalaci\u00f3n, encontraremos por lo general una lista de directorios como la siguiente.</li> </ul> <pre><code>cd $APPS_DIR/apps/zlib\nls\n</code></pre> <pre><code># salida del comando anterior\ninclude  lib  share\n</code></pre> <ul> <li>En esos directorios se encuentran los binarios con los cuales podremos hacer uso del software.</li> </ul>"}, {"location": "software/lista/", "title": "Lista de software", "text": ""}, {"location": "software/lista/#modulos-disponibles", "title": "M\u00f3dulos disponibles", "text": "<p>A continuaci\u00f3n se comparte la lista de software disponible:</p> <pre><code>------------------- /opt/ohpc/pub/moduledeps/gnu12-openmpi4 -------------------\n   adios/1.13.1            netcdf-fortran/4.6.0 (D)    scalapack/2.2.0\n   boost/1.81.0            netcdf/4.9.0         (D)    scalasca/2.5\n   dimemas/5.4.2           omb/6.1                     scorep/7.1\n   extrae/3.8.3            opencoarrays/2.10.1         sionlib/1.7.7\n   fftw/3.3.10             petsc/3.18.1                slepc/3.18.0\n   hypre/2.18.1            phdf5/1.10.8                superlu_dist/6.4.0\n   imb/2021.3              pnetcdf/1.12.3              tau/2.31.1\n   mfem/4.4                ptscotch/7.0.1              trilinos/13.4.0\n   mumps/5.2.1             py3-mpi4py/3.1.3\n   netcdf-cxx/4.3.1 (D)    py3-scipy/1.5.4\n\n----------------------- /opt/ohpc/pub/moduledeps/gnu12 ------------------------\n   R/4.2.1            mvapich2/2.3.7              pdtoolkit/3.25.1\n   gsl/2.7.1          netcdf-cxx/4.3.1            plasma/21.8.29\n   hdf5/1.10.8        netcdf-fortran/4.6.0        py3-numpy/1.19.5\n   likwid/5.2.2       netcdf/4.9.0                scotch/6.0.6\n   metis/5.1.0        openblas/0.3.21             superlu/5.2.1\n   mpich/3.4.3-ofi    openmpi4/4.1.6       (L)\n\n-------------------------- /opt/ohpc/pub/modulefiles --------------------------\n   EasyBuild/4.9.1          hwloc/2.7.2      (L)    os\n   autotools         (L)    intel/2023.2.1   (D)    papi/6.0.0\n   charliecloud/0.15        intel/2024.2.1          pmix/4.2.9\n   cmake/3.24.2             libfabric/1.19.0 (L)    prun/2.2        (L)\n   cuda/12.6                magpie/3.0              ucx/1.15.0      (L)\n   gnu12/12.3.0      (L)    ohpc             (L)    valgrind/3.19.0\n\n  Where:\n   D:  Default Module\n   L:  Module is loaded\n</code></pre>"}, {"location": "software/uso/", "title": "Uso de software", "text": ""}, {"location": "software/uso/#modulos", "title": "M\u00f3dulos", "text": "<p>Usted puede listar los m\u00f3dulos que se encuentran disponibles con el siguiente comando.</p> <pre><code>ml av \n# O tambi\u00e9n\nmodule avail\n</code></pre>"}, {"location": "software/uso/#buscar-modulos", "title": "Buscar m\u00f3dulos", "text": "<p>Usted tambi\u00e9n puede buscar m\u00f3dulos mediante el comando <code>avail</code>. Por ejemplo, para listar todas las versiones de MPICH 3, ejecutaremos:</p> <pre><code>module avail mpich/3\n</code></pre> <p>Y obtendremos una salida similar a:</p> <pre><code>--------------------------------------- /opt/apps/modulefiles ----------------------------------------\nmpich/1.5   mpich/3.1.4 mpich/3.2.1 mpich/3.3.2 mpich/3.4.0 mpich/4.0\n</code></pre>"}, {"location": "software/uso/#cargar-modulos", "title": "Cargar m\u00f3dulos", "text": "<p>Usted puede cargar un modulo a su ambiente de trabajo a traves del comando <code>module load</code>. Al cargar un modulo, usted carga todas las variables de ambiente necesarias para poder utilizar dicho paquete de software. </p> <p>Es importante tomar en cuenta que:</p> <ul> <li>El comando es case-sensitive a los nombres de los m\u00f3dulos</li> <li>Cuando usted usa <code>module load</code> se cargan tambi\u00e9n las dependencias del modulo. No es necesario cargarlas de manera separada.</li> <li>Cuando usted envi\u00e1 sus jobs que requieren de un m\u00f3dulo, no olvide a\u00f1adirlo con <code>module load</code> a su bash script.</li> </ul> <p>Por ejemplo, si desea cargar gcc versi\u00f3n 7.5.0, deber\u00e1 ejecutar:</p> <pre><code>module load gcc/7.5.0\n</code></pre> <p>Tambi\u00e9n puede cargar varios m\u00f3dulos al mismo tiempo:</p> <pre><code>module load gcc/7.5.0 mpich/3.3.2\n</code></pre>"}, {"location": "software/uso/#descargar-modulos", "title": "Descargar m\u00f3dulos", "text": "<p>Una vez terminado de usar el software, es recomendable hacer <code>module unload &lt;modulename&gt;</code>. Este proceso tambi\u00e9n se debe realizar e los scripts de los jobs.</p> <pre><code>module unload gcc/7.5.0\n</code></pre> <p>Tambi\u00e9n puede descargar todos los m\u00f3dulos a la vez con:</p> <pre><code>module purge\n</code></pre>"}, {"location": "software/uso/#coleccion-de-modulos", "title": "Colecci\u00f3n de m\u00f3dulos", "text": "<p>En casos cuando se trabaja con gran cantidad de m\u00f3dulos, puede ser molestoso estar cargando cada uno de ellos. Ante esto existe la opci\u00f3n de a\u00f1adir dicho m\u00f3dulos a una colecci\u00f3n y de este modo solo cargar la colecci\u00f3n en lugar que todos los m\u00f3dulos de manera individual. </p> <p>Guardar colecciones</p> <p>Para ello, usted deber\u00e1 cargar previamente los m\u00f3dulos que desea a\u00f1adir a la colecci\u00f3n y despues ejecutar. </p> <p><pre><code>module save &lt;collection-name&gt;\n</code></pre> Cargar colecciones</p> <p>Usted podr\u00e1 cargar la colecci\u00f3n creada con:</p> <p><pre><code>module restore &lt;collection-name&gt;\n</code></pre> Listar colecciones</p> <p>Para listar las colecciones creadas:</p> <pre><code>module savelist\n</code></pre>"}, {"location": "software/uso/#obtener-informacion-y-ayuda-de-los-modulos", "title": "Obtener informaci\u00f3n y ayuda de los m\u00f3dulos", "text": "<p>Si desea mostrar la informaci\u00f3n de configuraci\u00f3n de un modulo en especifico:</p> <pre><code>module show &lt;modulename&gt; #or\nmodule display &lt;modulename&gt;\n</code></pre> <p>Usted puede obtener una breve descripci\u00f3n sobre un m\u00f3dulo ejecutando:</p> <pre><code>module help &lt;modulename&gt;/&lt;version&gt;\n</code></pre> <p>Si usted no encuentra un paquete y considera que su instalaci\u00f3n como modulo podr\u00eda ser beneficiosa para otros usuarios m\u00e1s, puede escribirnos a khipu@utec.edu.pe para solicitar su instalaci\u00f3n.</p>"}, {"location": "soporte/", "title": "Soporte", "text": "<ul> <li>Si en caso necesita ayuda o requiere mayor informaci\u00f3n sobre Khipu, por favor escribir al correo  khipu@utec.edu.pe. </li> <li>Si ya posee sus credenciales, por favor genere un ticket a trav\u00e9s del portal de  mesa de ayuda. </li> </ul>"}, {"location": "soporte/mesa-de-ayuda/", "title": "\u00bfC\u00f3mo crear un ticket en Mesa de Ayuda?", "text": "<p>Khipu dispone de una secci\u00f3n en el portal de servicios ([servicedesk.utec.edu.pe][mesa-de-ayuda]) de UTEC. </p> <p></p> <p>Desde el portal de servicios cualquier usuario de Khipu podr\u00e1 solicitar ayuda con:</p> <ul> <li>Cuentas y accesos (desbloqueo de IP, restablecimiento de contrase\u00f1a o ampliaci\u00f3n de recursos)</li> <li>Conectividad (falla en conexi\u00f3n SSH, fallo en acceso a internet, falla en conexi\u00f3n a nodos de c\u00f3mputo)</li> <li>Software (instalaci\u00f3n de software de uso general, instalaci\u00f3n/actualizaci\u00f3n de software licenciado, reportar mal funcionamiento de software actual)</li> <li>Jobs (falla en env\u00edo a la fila de ejecuci\u00f3n, job permanece en fila y no se ejecuta o ampliaci\u00f3n del tiempo asignado al job)</li> </ul> <p></p> <p>Al generar su ticket por favor brinde los mayores detalles posibles. Incluya su nombre de usuario, el id de su job o capturas de pantalla si fuese posible. Esto ayudar\u00e1 a poder darle una mejor respuesta en un menor tiempo.</p> <p></p>"}, {"location": "tutoriales/apptainer/", "title": "Apptainer", "text": "<p>Apptainer (formerly Singularity)  is an open-source, secure, portable and easy-to-use container platform that allows users to create and run containers that package up pieces of software in a way that is portable and reproducible. You can build a container for Apptainer on your laptop, and then run it on a different PC, workstation, HPC cluster, cloud server, etc. Apptainer allows unprivileged users to use containers and prohibits privilege escalation within the container; users are the same inside and outside the container. Apptainer can import any container from OCI (Open Containers Initiative) registries. It means you can pull, run, and build from most containers on Docker Hub without changes. More information about Apptainer can be found on their official website.</p>"}, {"location": "tutoriales/apptainer/#overview-of-the-apptainer-interface", "title": "Overview of the Apptainer Interface", "text": "<p>Apptainer commands can be executed natively on the master or any compute node, without the need to load any additional module</p> <p>The <code>help</code> command gives an overview of Apptainer options and subcommands as follows:</p> <pre><code>$ apptainer help\n\nLinux container platform optimized for High Performance Computing (HPC) and\nEnterprise Performance Computing (EPC)\n\nUsage:\n  apptainer [global options...]\n\nDescription:\n  Apptainer containers provide an application virtualization layer enabling\n  mobility of compute via both application and environment portability. With\n  Apptainer one is capable of building a root file system that runs on any\n  other Linux system where Apptainer is installed.\n\nOptions:\n      --build-config    use configuration needed for building containers\n  -c, --config string   specify a configuration file (for root or\n                        unprivileged installation only) (default\n                        \"/etc/apptainer/apptainer.conf\")\n  -d, --debug           print debugging information (highest verbosity)\n  -h, --help            help for apptainer\n      --nocolor         print without color output (default False)\n  -q, --quiet           suppress normal output\n  -s, --silent          only print errors\n  -v, --verbose         print additional information\n      --version         version for apptainer\n\nAvailable Commands:\n  build       Build an Apptainer image\n  cache       Manage the local cache\n  capability  Manage Linux capabilities for users and groups\n  checkpoint  Manage container checkpoint state (experimental)\n  completion  Generate the autocompletion script for the specified shell\n  config      Manage various apptainer configuration (root user only)\n  delete      Deletes requested image from the library\n  exec        Run a command within a container\n  help        Help about any command\n  inspect     Show metadata for an image\n  instance    Manage containers running as services\n  key         Manage OpenPGP keys\n  keyserver   Manage apptainer keyservers\n  oci         Manage OCI containers\n  overlay     Manage an EXT3 writable overlay image\n  plugin      Manage Apptainer plugins\n  pull        Pull an image from a URI\n  push        Upload image to the provided URI\n  registry    Manage authentication to OCI/Docker registries\n  remote      Manage apptainer remote endpoints\n  run         Run the user-defined default command within a container\n  run-help    Show the user-defined help for an image\n  search      Search a Container Library for images\n  shell       Run a shell within a container\n  sif         Manipulate Singularity Image Format (SIF) images\n  sign        Add digital signature(s) to an image\n  test        Run the user-defined tests within a container\n  verify      Verify digital signature(s) within an image\n  version     Show the version for Apptainer\n\nExamples:\n  $ apptainer help &lt;command&gt; [&lt;subcommand&gt;]\n  $ apptainer help build\n  $ apptainer help instance start\n\nFor additional help or support, please visit https://apptainer.org/help/\n</code></pre>"}, {"location": "tutoriales/apptainer/#downloading-images", "title": "Downloading Images", "text": "<ul> <li>Container Images are executables that bundle together all necessary components for an application or an environment, like a template for containers.</li> <li>Containers are the runtime instance of images.</li> </ul> <p>Pre-built containers can be obtained from a variety of sources like:</p> <ul> <li>Apptainer/Singularity Hub</li> <li>Docker Hub</li> <li>NVIDIA NGC Catalog</li> <li>Other OCI registries</li> </ul> <p>You can use the pull and build commands to download images from an external resource like docker:</p> <pre><code>(master)$ apptainer pull docker://alpine\n(master)$ apptainer build &lt;container-name&gt;.sif docker://alpine\n</code></pre> <p>Remember!!  and  commands should be executed on the master node. The master node is the only one with internet access."}, {"location": "tutoriales/apptainer/#interacting-with-existing-containers", "title": "Interacting with existing containers", "text": ""}, {"location": "tutoriales/apptainer/#run", "title": "Run", "text": "<p>Once the image is downloaded, you are ready to run it.  As an example, we will download the lolcow container and run it.</p> <pre><code># Container downloading\n(master)$ apptainer pull docker://ghcr.io/apptainer/lolcow\nINFO:    Converting OCI blobs to SIF format\nINFO:    Starting build...\nCopying blob 5ca731fc36c2 done   | \nCopying blob 16ec32c2132b done   | \nCopying config fd0daa4d89 done   | \nWriting manifest to image destination\n2025/02/28 14:04:53  info unpack layer: sha256:16ec32c2132b43494832a05f2b02f7a822479f8250c173d0ab27b3de78b2f058\n2025/02/28 14:04:54  info unpack layer: sha256:5ca731fc36c28789c5ddc3216563e8bfca2ab3ea10347e07554ebba1c953242e\nINFO:    Creating SIF file...\n\n# Container running in the system host\n(master)$ apptainer run lolcow_latest.sif      \n ______________________________\n&lt; Fri Feb 28 14:05:17 -03 2025 &gt;\n ------------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre> <p>As we can see the container was download as an Apptainer Image File <code>lolcow_latest.sif</code> . This file was executed with the command <code>apptainer run &lt;container-image-name&gt;.sif</code>  . However, <code>run</code> is not the only command to run and interact with container, we will discuss this in the next lines. </p>"}, {"location": "tutoriales/apptainer/#shell", "title": "Shell", "text": "<p>You can create a new shell within your container and interact with it as though it were a virtual machine.</p> <pre><code>(master)$ apptainer shell lolcow_latest.sif   \nApptainer&gt;\n</code></pre> <p>The change in prompt ( from <code>(master)$</code> to <code>Apptainer&gt;</code>) indicates you are now inside the container. Additionally, your are the same user as you are in the host system and you can have access to the user home directory.</p> <pre><code># I executing apptainer in the master node\nApptainer&gt; hostname\nkhipu\n\n# My user in the host system is aturing, in apptainer too\nApptainer&gt; whoami\naturing\n\n# I can access my home directory inside the container\nApptainer&gt; pwd\n/home/aturing\n</code></pre> <p>Note: You can execute apptainer shell in the master node, but is highly recommended to do so using an interactive slurm job.  To do so, you must add the following command before your apptainer commands <code>srun --pty --mem=2G -p debug &lt;apptainer command&gt;</code>. </p> <p>Here is the above example using and interactive slurm job.</p> <pre><code># I will execute an apptainer shell in a compute node\nsrun --pty --mem=2G -p debug apptainer shell lolcow_latest.sif \nApptainer&gt; hostname\nn003\n</code></pre> <p>Remember that jobs in the <code>debug</code> partition has a time limit of 30 minutes. For long time running jobs, you must execute it using an slurm batch job. We will explain this later. </p>"}, {"location": "tutoriales/apptainer/#exec", "title": "Exec", "text": "<p>With <code>exec</code>command you can execute a custom command within a container. For example, to execute the <code>cowsay</code>program within the <code>lolcow_latest.sif</code> container:</p> <pre><code>[rubaldo@khipu ~]$ apptainer exec lolcow_latest.sif cowsay Khipu\n _______\n&lt; Khipu &gt;\n -------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre>"}, {"location": "tutoriales/apptainer/#working-with-files", "title": "Working with files", "text": "<p>Files on the system host are accesible from within the container.  </p> <pre><code>[rubaldo@khipu ~]$ echo \"Hello from Khipu\" &gt; $HOME/testfile.txt\n[rubaldo@khipu ~]$ apptainer exec lolcow_latest.sif cat $HOME/testfile.txt\nHello from Khipu\n</code></pre> <p>By default, Apptainer bind mounts <code>$HOME</code>, the current working directory, and additional system locations from the host into the container.</p> <p>References:</p> <ul> <li>https://apptainer.org/docs/user/main/quick_start.html</li> </ul>"}, {"location": "tutoriales/apptainer/#building-custom-images", "title": "Building custom images", "text": "<p>Apptainer allows users to build containers from a definition file (like Docker does with a dockerfile in ). Within this file you can add environment variables or install software dependencies to easily reproduce and share your containers.</p> <p>A definition file has a header and a body. The header determines the base container to begin with, and the body is further divided into sections that perform tasks such as software installation, environment setup, and copying files into the container from host system.  Further information of how to create the apptainer definition file can be found here.</p> <p>For example, we will create a <code>lolcow.def</code> file to define a container based on ubuntu and then install cowsay within. </p> <pre><code>BootStrap: docker\nFrom: ubuntu:24.04\n\n%post\n   apt-get -y update\n   apt-get -y install cowsay lolcat\n\n%environment\n   export LC_ALL=C\n   export PATH=/usr/games:$PATH\n\n%runscript\n   date | cowsay | lolcat\n\n%labels\n   Author Khipu\n   Exec: apptainer\n</code></pre> <p>In this example the header tells Apptainer to start with a <code>ubuntu:24.04</code> base image from Docker Container Library. The <code>%post</code> section is executed in build time after the base image has been downloaded. In this example, we are using it to update the package library and install <code>cowsay</code> and <code>lolcat</code>.  The <code>%environment</code> section defines environment variables  for the container. The <code>%runscript</code> section is used to place actions for the container when it is executed (This commands will not be executed at build time). Finally, the <code>%label</code> section is used to place information about the container like the author, how to used it, examples, etc. </p> <p>To build the container from the above file we need to execute <code>apptainer build &lt;container-name&gt;.sif &lt;container-definition-file&gt;.def</code></p> <pre><code>[rubaldo@khipu apptainer]$ apptainer build lolcow.sif lolcow.def \nINFO:    Starting build...\n...\nINFO:    Adding labels\nINFO:    Adding environment to container\nINFO:    Adding runscript\nINFO:    Creating SIF file...\nINFO:    Build complete: lolcow.sif\n</code></pre> <p>Then, to run the container is enough to execute <code>apptainer run lolcow.sif</code> or <code>./lolcow.sif</code>.</p>"}, {"location": "tutoriales/apptainer/#gpu-support", "title": "GPU support", "text": "<p>Apptainer has support for containers that use NVIDIA\u2019s CUDA GPU computing framework. The following lines show how to create and run GPU containers in Khipu.</p>"}, {"location": "tutoriales/apptainer/#download-images", "title": "Download images", "text": "<p>The first step as shown before is to pull and build the container image. As an example we will <code>pull</code> a nvida-cuda12.8.0 image.</p> <pre><code>[rubaldo@khipu]$ apptainer pull docker://nvidia/cuda:12.8.0-base-ubuntu20.04\nINFO:    Converting OCI blobs to SIF format\nINFO:    Starting build...\n...\nINFO:    Creating SIF file...\n\n# Or\n[rubaldo@khipu]$ apptainer build cuda12.sif docker://nvidia/cuda:12.8.0-base-ubuntu20.04\n</code></pre> <p>Remember: the <code>apptainer pull &lt;something&gt;</code> command only works on the master node. </p> <p>GPU nodes in Khipu are accesible through Slurm. In the following lines I will show how to compile and run your cuda code using Apptainer and Slurm.</p> <ul> <li>As a sample, use the gpu-info.cu code and compile it in the master node:</li> </ul> <pre><code># Load cuda module\n[rubaldo@khipu]$ ml load cuda\n[rubaldo@khipu]$ nvcc -o gpu_info gpu_info.cu\n</code></pre> <ul> <li>Then, to execute the code just run:</li> </ul> <pre><code>[rubaldo@khipu]$ srun --mem=1G -p gpu apptainer exec --nv cuda_12.8.0-base-ubuntu20.04.sif ./gpu_info\nCUDA Device(s) Found: 1\nDevice 0 Information:\nName: Tesla T4\nCompute Capability: 7.5\nTotal Global Memory: 14915 MB\nShared Memory per Block: 48 KB\nRegisters per Block: 65536\nMax Threads per Block: 1024\nMax Block Dimensions: (1024, 1024, 64)\nMax Grid Dimensions: (2147483647, 65535, 65535)\nClock Rate: 1590 MHz\nMemory Clock Rate: 5001 MHz\nMemory Bus Width: 256 bits\nTotal Constant Memory: 64 KB\nWarp Size: 32\nMultiprocessor Count: 40\n</code></pre> <p>As you can see the <code>--nv</code> is passed to the <code>exec</code> command to setup the environment to use an NVIDIA GPU and basic CUDA libraries. Without this flag the cuda devices  and libraries can not be used. This flag is not required at build time. </p> <ul> <li>Is highly recommended to compile your cuda code in the master node, because cuda images with nvidia compiler within (<code>devel</code> images) are much bigger than <code>base</code> container images.</li> </ul> <p>As a prove of concept, we can compile the same code using Apptainer. In order to do so we need to pull a <code>devel</code> cuda image like nvidia/cuda:12.5.1-devel-ubuntu20.04 (3.6 GB) which is more than 30 times bigger than a <code>base</code> image (~95 MB).</p> <pre><code>[rubaldo@khipu]$ apptainer pull docker://nvidia/cuda:12.5.1-devel-ubuntu20.04\nINFO:    Converting OCI blobs to SIF format\nINFO:    Starting build...\n...\nINFO:    Creating SIF file...\n</code></pre> <p>Then to compile the code, run:</p> <pre><code>[rubaldo@khipu]$ srun --mem=1G -p gpu apptainer exec --nv cuda_12.5.1-devel-ubuntu20.04.sif nvcc -o gpu_info gpu_info.cu\n</code></pre> <p>And finally to execute the code:</p> <pre><code>[rubaldo@khipu]$ srun --mem=1G -p gpu apptainer exec --nv cuda_12.5.1-devel-ubuntu20.04.sif ./gpu_info\nCUDA Device(s) Found: 1\nDevice 0 Information:\nName: Tesla T4\nCompute Capability: 7.5\nTotal Global Memory: 14915 MB\nShared Memory per Block: 48 KB\nRegisters per Block: 65536\nMax Threads per Block: 1024\nMax Block Dimensions: (1024, 1024, 64)\nMax Grid Dimensions: (2147483647, 65535, 65535)\nClock Rate: 1590 MHz\nMemory Clock Rate: 5001 MHz\nMemory Bus Width: 256 bits\nTotal Constant Memory: 64 KB\nWarp Size: 32\nMultiprocessor Count: 40\n</code></pre> <p>To practice the above commands you can try to execute it all our gpu nodes adding the <code>--nodelist=&lt;name of a gpu node&gt;</code> to the srun command. To check the list of gpu nodes execute <code>sinfo</code>.</p> <p>In all the previuos examples the <code>srun</code> commands was used to launch the slurm jobs. This command is suitable for short time jobs, but if your job requires much more time you should launch your jobs in batch mode with <code>sbatch</code>.</p> <p>More information about Apptainer GPU support can be found here.</p>"}, {"location": "tutoriales/apptainer/#interactive-mode", "title": "Interactive mode", "text": "<p>Sometimes you want to interact with your container like if you were on a shell. You can do this using an interactive slurm job. Interactive jobs should be executed on the <code>debug-gpu</code> partition and has a time limit of 30 minutes. Remember that container in apptainer are inmutable after build.</p> <pre><code>[rubaldo@khipu]$ srun --pty -p debug-gpu apptainer run --nv cuda_12.8.0-base-ubuntu20.04.sif\nApptainer&gt;\n\n# To check the nvidia driver\nApptainer&gt; nvidia-smi\nSun Mar  2 09:20:22 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       On  |   00000000:37:00.0 Off |                    0 |\n| N/A   78C    P0             51W /   70W |   13831MiB /  15360MiB |     55%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n...\n</code></pre>"}, {"location": "tutoriales/apptainer/#apptainer-cache", "title": "Apptainer Cache", "text": "<p>When you generate a SIF image from remote sources, Apptainer will cache the image. By default, the cache folder will be created in <code>HOME</code> environmental variable (<code>$HOME/.apptainer/cache</code>). The <code>apptainer cache</code> command allows you to list and clean up your cache.</p> <pre><code># List your cache\n[rubaldo@khipu]$ apptainer cache list\nThere are 4 container file(s) using 7.31 GiB and 88 oci blob file(s) using 13.18 GiB of space\nTotal space used: 20.49 GiB\n\n# The same command with details\napptainer cache list -v\nNAME                     DATE CREATED           SIZE             TYPE\n03bb9eb021f579ed871d5f   2025-03-02 07:52:09    4.41 MiB         blob\n093f9cb4ed5900be5b069a   2025-02-08 14:25:21    0.18 KiB         blob\n...\n\nThere are 4 container file(s) using 7.31 GiB and 88 oci blob file(s) using 13.18 GiB of space\nTotal space used: 20.49 GiB\n\n# Clean you cache\napptainer cache clean\n\n# Clean you cache files older than 15 days\napptainer cache clean --days 15\n</code></pre> <p>Try to regularly free up your apptainer cache.</p>"}, {"location": "tutoriales/apptainer/#slurm-submission-script", "title": "SLURM Submission Script", "text": "<p>You can launch your Apptainer jobs in batch mode with an slurm script. It is highly recommended when your job will take a lot of time executing. As an example, the <code>lolcow_latest.sif</code>, container of the first example, will be run using a <code>lolcow.slurm</code> submission file.</p> <pre><code>#!/bin/bash\n\n## Slurm Directives\n#SBATCH --job-name=apptainer_lolcow\n#SBATCH --output=apptainer_lolcow-%j.out\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem-per-cpu=1G\n#SBATCH -p debug\n\n## Load modules, if needed\n\n## Place to the directory where you container is, for example $HOME\ncd $HOME\n\n## Run the program using use 'srun'.\nsrun apptainer run lolcow_latest.sif \n</code></pre> <p>In the above script, <code>1 CPU</code> with <code>1GB RAM</code> per CPU was requested in the <code>debug</code> partition for the task. This container will run only one (<code>--ntasks=1</code>), if you want to execute it more times try changing the value of <code>--ntasks=</code>, but remember that this only works when your commands is executed with the <code>srun</code> command.</p> <p>To submit this script, just run:</p> <pre><code>[rubaldo@khipu]$ sbatch lolcow.slurm\n# When the job finish, check you output with cat\n[rubaldo@khipu]$ cat apptainer_lolcow-4377.out \n _____________________________\n&lt; Mon Mar 2 11:36:49 -05 2025 &gt;\n -----------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre> <p>For NVIDIA GPU jobs, in this case using the <code>cuda_12.8.0-base-ubuntu20.04.sif</code> image, the Slurm script <code>gpu_info.slurm</code> should be:</p> <pre><code>#!/bin/bash\n\n## Slurm Directives\n#SBATCH --job-name=apptainer_gpu_info\n#SBATCH --output=apptainer_gpu_info-%j.out\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem-per-cpu=1G\n#SBATCH --gres=gpu:1\n#SBATCH -p debug-gpu\n\n## Load modules, if needed\n\n## Place to the directory where you container is, for example $HOME\ncd $HOME/apptainer\n\n## Run the program using use 'srun'.\nsrun apptainer exec --nv cuda_12.8.0-base-ubuntu20.04.sif ./gpu_info\n</code></pre> <p>Then, to submit this script, just run:</p> <pre><code>[rubaldo@khipu]$ sbatch gpu_info.slurm\n# Wait until the job finish. Then you will have an output like this:\n[rubaldo@khipu]$ cat apptainer_gpu_info-4576.out \nCUDA Device(s) Found: 1\nDevice 0 Information:\nName: Tesla T4\nCompute Capability: 7.5\nTotal Global Memory: 14915 MB\nShared Memory per Block: 48 KB\nRegisters per Block: 65536\nMax Threads per Block: 1024\nMax Block Dimensions: (1024, 1024, 64)\nMax Grid Dimensions: (2147483647, 65535, 65535)\nClock Rate: 1590 MHz\nMemory Clock Rate: 5001 MHz\nMemory Bus Width: 256 bits\nTotal Constant Memory: 64 KB\nWarp Size: 32\nMultiprocessor Count: 40\n</code></pre> <p>If you want to get notified when your job fails or finish, don\u2019t forget to add the following lines to you slurm script.</p> <pre><code>#SBATCH --mail-type=fail        # send email when job begins\n#SBATCH --mail-type=end          # send email when job ends\n#SBATCH --mail-user=&lt;your email&gt;\n</code></pre> <p>References:</p> <p>https://hpc.nmsu.edu/discovery/software/apptainer/using-containers/</p>"}, {"location": "tutoriales/reinicio-job-pytorch/", "title": "Reinicio de jobs con PyTorch", "text": "<p>El cluster Khipu es una herramienta valiosa cuyos recursos son compartidos y limitados. Lamentablemente no se puede ofrecer recursos infinitos siempre, ya que limitar\u00eda su disponibilidad para todos. Ante esto el cluster mantiene una pol\u00edtica de restricciones en el tiempo de ejecuci\u00f3n basada en ciclos. </p> <p>Un ciclo de ejecuci\u00f3n es la cantidad m\u00e1xima de tiempo que un trabajo o job puede ser ejecutado de manera ininterrumpida en el cluster. Una vez su ciclo de ejecuci\u00f3n llega al tiempo m\u00e1ximo, su trabajo ser\u00e1 terminado por el gestor de colas. \u00bfPero qu\u00e9 pasa cuando su trabajo requiere un tiempo mayor al que se disponible en un ciclo de ejecuci\u00f3n? Pues, puede usar varios ciclos de ejecuci\u00f3n para poder completarlo. De esta manera, si el cluster se encuentra libre, usted podr\u00e1 obtener todos los ciclos que necesite inmediamente despues de su anterior. Y si el cluster tiene demanda, una vez acabado su anterior ciclo, su trabajo ser\u00e1 encolado a la espera de que se liberen los recursos solicitados para poder ejecutar un nuevo ciclo de ejecuci\u00f3n. Y as\u00ed su trabajo podr\u00e1 usar todos los ciclos que necesite para poder completarse.</p> <p>Ahora que se ha explicado como funcionan los ciclos de ejecuci\u00f3n en Khipu es importante mostrarlo con un ejemplo \u00bfno? En esta gu\u00eda se va mostrar como podemos entrenar un modelo de PyTorch usando varios ciclos de ejecuci\u00f3n en el cluster. Este ejemplo, aunque sencillo, puede ser luego adaptado y extendido para sus diferentes casos de uso.</p>"}, {"location": "tutoriales/reinicio-job-pytorch/#prerequisitos", "title": "Prerequisitos", "text": "<ul> <li>Tener una cuenta de Khipu activa</li> <li>Cargar los m\u00f3dulos de <code>Python3</code> <pre><code>ml load python3\n# Crear un entorno virtual\npython3 -m venv venv\nsource venv/bin/activate\npip install torch\n</code></pre></li> </ul>"}, {"location": "tutoriales/reinicio-job-pytorch/#paso-a-paso", "title": "Paso a paso", "text": "<p>Para el siguiente tutorial vamos a usar el siguiendo modelo en PyTorch:</p> <pre><code>import torch\nfrom torch import nn # nn contains all of PyTorch's building blocks for neural networks\n\n#########################\n## Inicializaci\u00f3n de cuda\n#########################\n\n\nprint(f\"PyTorch version: {torch.__version__}\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Usando como device: {device}\")\n\n# Funci\u00f3n utilitaria para configurar los seed en GPU o CPU\ndef set_seed(seed):\n    torch.manual_seed(seed)\n    if device == \"cuda\": torch.cuda.manual_seed(seed)    \n\n#########################\n## Creaci\u00f3n del dataset: creaci\u00f3n de un conjunto de valores para la funci\u00f3n f con adici\u00f3n de ruido\n#########################\n\n\ndef f(x): return 7*x*x - x + 2\nprint(\"\\nFunci\u00f3n original\\t\\t : f(x) = 7x^2 - x + 2\")\n\nset_seed(42)\n\nX_all = torch.arange(-3.0, 3.0, 0.01, dtype=torch.float64,device=\"cpu\").unsqueeze(dim=1)\ny_all_clean = f(X_all)\ny_all = y_all_clean + (torch.rand(size=X_all.shape, device=\"cpu\")*4.0 - 2.0) \n\n# Envio de los datos al device\nX_all = X_all.to(device)\ny_all_clean = y_all_clean.to(device)\ny_all = y_all.to(device)\n\n#############################\n## Separar datos en training, testing and validation data\n############################\n\ndef sample_values_from_dataset(X, y, n_samples, random_seed=1969):\n    set_seed(random_seed)\n    # retrieve index to further use in the complete dataset\n    random_indices = torch.randperm(n=X_all.shape[0], device=\"cpu\")\n    random_indices = random_indices.to(device)\n    chosen_indices = random_indices[:n_samples]\n    return X[chosen_indices,:], y[chosen_indices,:]\n\n# Obtener una muestra aleatoria de 16 n\u00fameros\nX, y = sample_values_from_dataset(X_all, y_all, 16)\n\nX_train, y_train = X[0:8], y[0:8]\nX_val, y_val = X[8:12], y[8:12]\nX_test, y_test = X[12:16], y[12:16]\n\nprint(f\"Forma del set de entrenamiento\\t : X = {X_train.shape}, y = {y_train.shape}\")\nprint(f\"Forma del set de validaci\u00f3n\\t : X = {X_val.shape}, y = {y_val.shape}\")\nprint(f\"Forma del set de testeo\\t\\t : X = {X_test.shape}, y = {y_test.shape}\")\n\n\n#################################\n## Creaci\u00f3n del modelo\n#################################\n\nclass PolynomialRegressionModel(nn.Module):\n    def __init__(self, polynomial_degree):\n        super().__init__()\n        self.d = polynomial_degree\n\n        self.coefficients = nn.ParameterList([nn.Parameter(torch.randn(1, dtype=torch.float64)) for i in range(self.d+1)])\n\n    def forward(self, X):\n        result = torch.zeros(size=(X.shape[0],1), device=X.device)\n        for i in range(self.d+1):\n            result = result + (torch.pow(X,i) * self.coefficients[i])\n        return result\n\n    def __str__(self):\n        equation = f\"f(x) = {self.coefficients[self.d].item():.4f} * x^{self.d}\"\n        for i in range(self.d-1, -1, -1):\n            equation = equation + f\" + {self.coefficients[i].item():.4f} * x^{i}\"\n        return equation\n\n# Lets set the random number generator seed to ensure we always generate the same model whenever we re-execute this code block.\nset_seed(1969)\n\nmy_model = PolynomialRegressionModel(polynomial_degree=2).to(device)\n\nprint(\"\\n-- Mi modelo lineal --\")\nprint(\"La funci\u00f3n de mi modelo:\", my_model)\n\n\n##########################################\n## Entrenamiento de mi modelo\n#########################################\n\nimport os\nimport time\n\nEPOCH_SAVE_PATH = \"last_completed_epoch.txt\"\nMODEL_SAVE_PATH = \"last_model_state.pth\"\n\n# funci\u00f3n utilitaria para recuperar la \u00faltima epoca ejecutada\ndef get_last_completed_epoch():\n    if os.path.exists(EPOCH_SAVE_PATH):\n        with open(EPOCH_SAVE_PATH, \"r\") as file:\n            last_completed_epoch = int(file.read())\n            file.close()\n    else:\n        last_completed_epoch = -1\n    return last_completed_epoch\n\n\ndef train_model_v1(model, \n                   X_train, y_train, \n                   X_val, y_val,\n                   learning_rate = 0.01,\n                   number_of_epochs = 10,\n                   verbosity_skip_level = 1):\n    loss_fn = nn.L1Loss() \n    optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate)\n\n    curr_epoch = 0\n    while curr_epoch &lt; number_of_epochs:\n\n        # Verifico si ejecut\u00e9 previamente mi modelo\n        last_epoch_completed = get_last_completed_epoch()\n        if last_epoch_completed &gt;= curr_epoch:\n            print(f\"Restaurando el \u00faltimo estado del modelo en la \u00e9poca: {last_epoch_completed}\")\n            # continuar con la siguiente epoca y restauro estado\n            curr_epoch = last_epoch_completed + 1\n            model = torch.load(f=MODEL_SAVE_PATH, weights_only=False)\n\n        # Entrenamiento\n        model.train()\n        y_hat = model(X_train)\n        loss = loss_fn(y_hat, y_train)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Validaci\u00f3n\n        model.eval()\n        with torch.inference_mode():\n            val_hat = model(X_val)\n            val_loss = loss_fn(val_hat, y_val)\n            if (verbosity_skip_level &gt; 0) and (curr_epoch % verbosity_skip_level == 0):\n                print(f\"Epoca: {curr_epoch} | MAE Train Loss: {loss} | MAE Validation Loss: {val_loss} \")\n\n\n        # Guardamos el estado del modelo\n        torch.save(model, f=MODEL_SAVE_PATH) \n        with open(EPOCH_SAVE_PATH, \"w\") as file:\n            file.write(str(curr_epoch))\n            file.close()\n\n        curr_epoch += 1\n        time.sleep(0.01)\n\n#####################################\n## Ejecuci\u00f3n\n#####################################\n\nprint(\"\\n** Entrenando mi modelo hasta 1000 epocas **\")\ntrain_model_v1(my_model, X_train, y_train, X_val, y_val,\n               learning_rate = 0.01, number_of_epochs = 1000,\n               verbosity_skip_level = 100)\n\nprint(\"\\n La funci\u00f3n de mi modelo final:\", my_model)\n# Eliminando archivo de epocas\nif os.path.exists(EPOCH_SAVE_PATH):\n  os.remove(EPOCH_SAVE_PATH)\n</code></pre> <p>El siguiente job script incluye el par\u00e1metro <code>--signal</code> el cual se usa para enviar una se\u00f1al 30 segundos antes de quel job se termine por falta de tiempo. Cuando esto ocurre se captura la se\u00f1al y se a\u00f1ade un handler propio para ella. En este handler se guarda el output actual en otro archivo y se env\u00eda una solicitud de requeue. Un job requeue permite volver a enviar a ejecuci\u00f3n el job actual. De esta manera, se solicita un nuevo ciclo de ejecuci\u00f3n antes de que termine el actual. Para evitar que las solicitudes de requeue no tengan fin, se establece un par\u00e1metro que establece la cantidad m\u00e1xima de reinicios. </p> <pre><code>#!/bin/bash\n\n## Slurm Directives\n#SBATCH --job-name sample-pytorch\n#SBATCH --output sample-pytorch-%J.out\n#SBATCH --error sample-pytorch-%J.err\n#SBATCH -t 00:01:00\n#SBATCH -p debug-gpu\n#SBATCH --signal=B:SIGTERM@30\n\nexport PYTHONUNBUFFERED=TRUE\n##############################################################\n##  Gather some information from the job and setting limits ##\n\nmax_restarts=4      # tweak this number to fit your needs\nscontext=$(scontrol show job ${SLURM_JOB_ID})\nrestarts=$(echo ${scontext} | grep -o 'Restarts=[0-9]*****' | cut -d= -f2)\noutfile=sample-pytorch-${SLURM_JOB_ID}.out\n\n##                                                          ##\n##############################################################\n##  Build a term-handler function to be executed            ##\n##      when the job gets the SIGTERM                       ##\n\nterm_handler()\n{\n    echo \"Executing term handler at $(date)\"\n    if [[ $restarts -lt $max_restarts ]];then\n        # Copy the log file because it will be overwriten\n        cp -v \"${outfile}\" \"${outfile}.${restarts}\"\n        scontrol requeue ${SLURM_JOB_ID}\n        exit 0\n    else\n        echo \"Your job is over the Maximun restarts limit\"\n        exit 1\n    fi\n}\n\n## Call the function when the jobs recieves the SIGTERM     ##\ntrap 'term_handler' SIGTERM\n\n# print some job-information\ncat &lt;&lt;EOF\nSLURM_JOB_ID:         $SLURM_JOB_ID\nSLURM_JOB_NAME:       $SLURM_JOB_NAME\nSLURM_JOB_PARTITION:  $SLURM_JOB_PARTITION\nSLURM_SUBMIT_HOST:    $SLURM_SUBMIT_HOST\nRestarts:             $restarts\nEOF\n\n\n##                                                          ##\n##############################################################\n##          Here begins your actual program                 ##\n\n##  \n\n## Place to your working directory, for example $HOME\ncd ~/my-model-dir\n\n## Load modules\nml load python3\nsource venv/bin/activate\n\nsrun python3 my_model.py\n</code></pre> <p>Note</p> <p>Si por la naturaleza de su trabajo no puede adaptarlo para su ejecuci\u00f3n en ciclos, es posible aumentarle su tiempo l\u00edmite de ejecuci\u00f3n. Sin embargo, estos casos deber\u00edan ser la excepci\u00f3n y no la regla.</p>"}, {"location": "tutoriales/vs-code-remote/", "title": "Visual Studio Code Remoto en Khipu", "text": "<p>En este tutorial vamos a mostrar c\u00f3mo conectarse a un nodo de c\u00f3mputo de Khipu usando Remote - SSH. Remote - SSH, es una extensi\u00f3n de Visual Studio que facilita la conexi\u00f3n a un servidor remoto a trav\u00e9s del protocolo SSH. A trav\u00e9s de esta herramienta es posible:</p> <ul> <li>Crear, editar y eliminar archivos de manera directa en el servidor remoto.</li> <li>Copiar archivos locales al servidor remoto usando <code>drag-and-drop</code>.</li> <li>Descargar sus archivos remotos.</li> <li>Crear sesiones de terminal y ejecutar comandos.</li> <li>Redirecci\u00f3n autom\u00e1tica de puertos, y m\u00e1s.</li> </ul> <p>Hasta ahora todo esto era posible de hacer solamente en el nodo l\u00edder. Sin embargo, su uso se limitaba a la ejecuci\u00f3n de tareas administrativas y comandos cortos. A partir de ahora ser\u00e1 posible obtener los beneficios listados directamente en un nodo de c\u00f3mputo. Y lo mejor de todo es que cada sesi\u00f3n se instanciar\u00e1 de manera autom\u00e1tica a un job en Slurm. </p> <p>Info</p> <p>Por el momento, el \u00fanico nodo habilitado para este fin ser\u00e1 el nodo ds001 de la particion de data-science. Cada sesi\u00f3n contar\u00e1 con un reserva de 8 n\u00facleos CPU, 32GB de RAM, 4 shards de GPU y un tiempo l\u00edmite de 4 horas. No es posible tener m\u00e1s de una sesi\u00f3n por usuario y una vez acabado el tiempo l\u00edmite, se tendr\u00e1 que instanciar nuevamente la sesi\u00f3n. </p> <p>A continuaci\u00f3n se muestran los pasos a seguir para configurar nuestra sesi\u00f3n de Visual Studio directamente en un nodo de c\u00f3mputo.</p>"}, {"location": "tutoriales/vs-code-remote/#instalacion", "title": "Instalaci\u00f3n", "text": ""}, {"location": "tutoriales/vs-code-remote/#requisitos", "title": "Requisitos", "text": "<ul> <li>Visual Studio Code</li> <li>Remote - SSH</li> </ul> <p>Para instanciar nuestro Visual Studio haremos uso del script vscode-remote-hpc que fue adaptado para su funcionamiento en Khipu. Este script se encargar\u00e1 de configurar una sesi\u00f3n de Remote - SSH, a partir del cual usted podr\u00e1 iniciar un batch job, o reusar uno existente, directamente desde su Visual Studio. Este script funciona para Linux , Windows  y Mac . </p>  Linux y    MacOS Windows <ul> <li>Abrimos una sesi\u00f3n de terminal y ejecutaremos el siguiente comando:</li> </ul> <p><pre><code>curl -fsSL https://raw.githubusercontent.com/khipu-utec/vscode-remote-hpc/refs/heads/main/client/setup.sh | bash\n</code></pre> - Seguiremos los pasos que se nos indique en pantalla, tal y como se muestra a continuaci\u00f3n:</p> <p></p> <ul> <li>Abrimos una sesi\u00f3n de PowerShell y ejecutaremos el siguiente comando: </li> </ul> <pre><code>irm https://raw.githubusercontent.com/khipu-utec/vscode-remote-hpc/refs/heads/main/client/setup.ps1 | iex\n</code></pre> <ul> <li>Seguiremos los pasos que se nos indique en pantalla, tal y como se muestra a continuaci\u00f3n:</li> </ul> <p></p>"}, {"location": "tutoriales/vs-code-remote/#como-usar", "title": "\u00bfC\u00f3mo Usar?", "text": "<p>Una vez realizado el paso anterior, <code>vscode-remote-khipu</code> estar\u00e1 disponible en el Remote Explorer de Visual Studio.</p> <p></p> <p>Al hacer click en \u00e9l, autom\u00e1ticamente se lanzar\u00e1 un batch job en Khipu. Deberemos esperar unos momentos hasta que el job se inicie y podamos conectarnos a \u00e9l. Si nos conectamos al cluster y observamos la fila de slurm con <code>squeue --me</code> notaremos que existe un nuevo job llamado <code>vscode-remote</code>. </p> <p>Info</p> <p>Si no logramos observar nuestro job, es probable que se deba a que la fila de acceso a ese nodo ya se llen\u00f3 y debamos intentar m\u00e1s tarde. </p> <p>Luego que la sesi\u00f3n termine de configurarse, podremos seleccionar un directorio para trabajar y usar nuestro Visual Studio remoto. Puede crear previamente un directorio para trabajar, o hacerlo directamente desde su <code>$HOME</code>.</p> <p>Es importante mencionar que el job permanecer\u00e1 en ejecuci\u00f3n hasta que el tiempo l\u00edmite se alcance. Es por ello que s\u00ed termina antes del tiempo l\u00edmite, deber\u00e1 cancelar su job manualmente para liberar espacio en la cola. Recuerde que el cluster es un compartido por todos y por ello debemos hacer un uso responsable y emp\u00e1tico de sus recursos. </p> <p>Warning</p> <p> Cerrar su Visual Studio no cancela autom\u00e1ticamente su job, deber\u00e1 hacerlo de manera manual!</p>"}, {"location": "tutoriales/vs-code-remote/#como-terminar-mi-sesion", "title": "\u00bfComo terminar mi sesi\u00f3n?", "text": "<p>Para cancelar su job puede hacerlo con el cl\u00e1sico <code>scancel &lt;job-id&gt;</code> usando el <code>job-id</code> de su sesi\u00f3n, o ejecutando:</p> <pre><code>vscode-remote cancel\n</code></pre>"}, {"location": "tutoriales/vs-code-remote/#recomendaciones-generales", "title": "Recomendaciones Generales", "text": "<p>Actualmente, estamos experimentando con esta nueva herramienta y lo estamos haciendo \u00fanicamente en el nodo ds001 de la particion de data-science. Ese nodo cuenta con GPU y acceso a internet (a diferencia de los dem\u00e1s nodos de c\u00f3mputo). Nuestra intenci\u00f3n es que este nodo sirva para ejecutar notebooks de Python de manera similar a como se realiza en Google Colab, sin embargo no contamos con recursos infinitos para poder proveer un acceso ilimitado a las sesiones en Visual Studio. Es por ello que dejamos las siguientes recomendaciones.</p> <ul> <li>Si va a ejecutar trabajos de Inteligencia Artificial, use este nodo para configurar su <code>virtual enviroment</code>, instalar sus dependencias, descargar sus datos, visualizar la cantidad de par\u00e1metros que ser\u00e1n optimizados y hacer una prueba inicial de la ejecuci\u00f3n de su modelo. </li> <li>Si ve que su modelo tiene una gran cantidad de par\u00e1metros (mayor a 4GB de GPU RAM) y/o demorar\u00e1 en ejecutarse, genere su script en Slurm y m\u00e1ndelo de la manera tradicional.</li> <li>No genere una sesi\u00f3n para empezar a codear su modelo desde cero. Recuerde que cada sesi\u00f3n reserva una cantidad grande de recursos que ser\u00edan mal aprovechados realizando esa tarea. Puede usar herramientas como Google Colab para codear sus modelos y una vez listos, traerlos a Khipu para su ejecuci\u00f3n. Recuerde que, al igual que usted, hay alguien m\u00e1s esperando por usar Khipu.</li> <li>No olvide cerrar su sesi\u00f3n al t\u00e9rmino de su trabajo.</li> </ul>"}, {"location": "anuncios/archive/2025/", "title": "2025", "text": ""}, {"location": "anuncios/category/status/", "title": "status", "text": ""}]}